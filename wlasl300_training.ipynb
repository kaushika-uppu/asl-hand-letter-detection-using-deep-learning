{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv44qgPrpcO2"
   },
   "source": [
    "# WLASL Training\n",
    "\n",
    "The Word-Level American Sign Language (WLASL) dataset consists of approximately 12,000 videos of around 2,000 common words.\n",
    "\n",
    "For training, we use the LSTM neural network for sequence classification\n",
    "and TensorFlow/Keras for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4sFqii9pqc3"
   },
   "source": [
    "## Set-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrxgYOQkp6ms"
   },
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MtvaPtbp6K2",
    "outputId": "7e95abbe-e892-4725-a4b9-c2567d85f885"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages = [\n",
    "    \"numpy==1.26.4\",\n",
    "    \"protobuf==4.25.3\",\n",
    "    \"mediapipe==0.10.21\",\n",
    "    \"opencv-python-headless==4.8.1.78\",\n",
    "    \"scikit-learn==1.3.2\",\n",
    "    \"matplotlib\"\n",
    "]\n",
    "\n",
    "print(\"Installing dependencies...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3lpZ6Hmp-kV",
    "outputId": "12b49b91-8766-49b9-ff85-94baad81ba9b"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Verifying installations...\")\n",
    "print(f\"  Python version: {sys.version.split()[0]}\")\n",
    "print(f\"  TensorFlow: {tf.__version__}\")\n",
    "print(f\"  MediaPipe: {mp.__version__}\")\n",
    "print(f\"  OpenCV: {cv2.__version__}\")\n",
    "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\") # Should be 1.26.4\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ziLyOq5qPs9"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XD0ahNECprYu",
    "outputId": "883ceae5-e8ec-49b9-d705-bb57e31948ab"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "print(\"Importing libraries...\")\n",
    "\n",
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "from typing import List, Sequence\n",
    "\n",
    "# Third-party imports\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"OpenCV imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"OpenCV import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    from mediapipe.tasks import python as mp_python\n",
    "    from mediapipe.tasks.python import vision\n",
    "    print(\"MediaPipe imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"MediaPipe import failed: {e}\")\n",
    "    print(\"  Run the installation cell again.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"NumPy imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"NumPy import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    print(\"TensorFlow/Keras imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"TensorFlow import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    print(\"Scikit-learn imported\")\n",
    "except ImportError as e:\n",
    "    print(f\"Scikit-learn import failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Constants\n",
    "NUM_HANDS = 2\n",
    "NUM_LANDMARKS = 21\n",
    "COORDS = 3\n",
    "FEATURE_VECTOR_LEN = NUM_HANDS * NUM_LANDMARKS * COORDS\n",
    "WRIST_IDX = 0\n",
    "MIDDLE_MCP_IDX = 9\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDG0CTSqsPjW"
   },
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4f-2ifLpsQNQ",
    "outputId": "120a45fa-8b91-4a22-b232-4f19448ee9f6"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE8q_igqiHW"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnFHNAXcqkYK",
    "outputId": "5ad4e7d2-748e-41da-dd2b-dd054115a423"
   },
   "outputs": [],
   "source": [
    "# File paths\n",
    "NPZ_PATH = \"wlasl_landmarks.npz\"  # Or use Drive path: \"/content/drive/MyDrive/WLASL Dataset/wlasl_landmarks.npz\"\n",
    "LABELS_OUTPUT = \"wlasl_labels.npy\"\n",
    "MODEL_OUTPUT = \"wlasl_sequence_model.keras\"\n",
    "\n",
    "# Training parameters\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "LSTM_UNITS = [128, 64]\n",
    "DENSE_UNITS = 64\n",
    "DROPOUT = 0.5\n",
    "PATIENCE = 10                 # Early stopping patience\n",
    "\n",
    "print(\"Configuration loaded\")\n",
    "print(f\"\\nLooking for preprocessed data at: {NPZ_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1Zb40HFpEbv"
   },
   "source": [
    "### Build LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HO3dE4xLo9F8",
    "outputId": "f3dd0e44-e9dc-4631-ee3a-68499bbc0d1e"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape: tuple,\n",
    "    num_classes: int,\n",
    "    lstm_units: list,\n",
    "    dense_units: int,\n",
    "    dropout: float,\n",
    "    learning_rate: float,\n",
    ") -> keras.Model:\n",
    "    \"\"\"\n",
    "    Build LSTM model for sequence classification.\n",
    "\n",
    "    Architecture:\n",
    "    - Masking layer (ignores padded zeros)\n",
    "    - LSTM layer 1 (with return_sequences=True)\n",
    "    - Dropout\n",
    "    - LSTM layer 2\n",
    "    - Dropout\n",
    "    - Dense layer (ReLU)\n",
    "    - Output layer (Softmax)\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Masking(mask_value=0.0),  # Ignore padded frames\n",
    "        layers.LSTM(lstm_units[0], return_sequences=True, use_cudnn=False), # Disable cuDNN\n",
    "        layers.Dropout(dropout),\n",
    "        layers.LSTM(lstm_units[1], use_cudnn=False), # Disable cuDNN\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(dense_units, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Model builder function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neuXidCopIdj"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "id": "bHLp8EdbpCEs",
    "outputId": "f08c6634-6b67-45a2-a473-d3d1ac978aec"
   },
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "keras.utils.set_random_seed(42)\n",
    "try:\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "\n",
    "data = np.load(NPZ_PATH)\n",
    "sequences = data[\"sequences\"].astype(np.float32)\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "print(f\"Loaded {sequences.shape[0]} sequences\")\n",
    "print(f\"  Shape: {sequences.shape}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "np.save(LABELS_OUTPUT, label_encoder.classes_)\n",
    "print(f\"Saved label order to {LABELS_OUTPUT} ({len(label_encoder.classes_)} classes)\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sequences,\n",
    "    encoded_labels,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=42,\n",
    "    stratify=encoded_labels,\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Build model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"\\nBuilding model...\")\n",
    "print(f\"  Input shape: {input_shape}\")\n",
    "print(f\"  Number of classes: {num_classes}\")\n",
    "\n",
    "model = build_model(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    lstm_units=LSTM_UNITS,\n",
    "    dense_units=DENSE_UNITS,\n",
    "    dropout=DROPOUT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_OUTPUT,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Train model\n",
    "print(f\"\\nStarting training for up to {EPOCHS} epochs...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xhoiIRvpKp6"
   },
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJre9owTpNma"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "print(\"Generating predictions on test set...\")\n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST ACCURACY: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\"*60)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Save final model (ensure it's saved even if early stopping didn't trigger)\n",
    "model.save(MODEL_OUTPUT)\n",
    "print(f\"\\nModel saved to {MODEL_OUTPUT}\")\n",
    "print(f\"Labels saved to {LABELS_OUTPUT}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTo use this model:\")\n",
    "print(f\"1. Download '{MODEL_OUTPUT}' and '{LABELS_OUTPUT}'\")\n",
    "print(f\"2. Load them in your inference script\")\n",
    "print(f\"3. Process videos the same way (landmarks -> normalize -> predict)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2P-61Y4pSOC"
   },
   "source": [
    "### Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poZ6GXfIpS7z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
