{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WLASL Training\n",
        "\n",
        "The Word-Level American Sign Language (WLASL) dataset consists of approximately 12,000 videos of around 2,000 common words.\n",
        "\n",
        "For training, we use the LSTM neural network for sequence classification\n",
        "and TensorFlow/Keras for model training."
      ],
      "metadata": {
        "id": "Vv44qgPrpcO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-Up"
      ],
      "metadata": {
        "id": "z4sFqii9pqc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Dependencies"
      ],
      "metadata": {
        "id": "JrxgYOQkp6ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "packages = [\n",
        "    \"numpy==1.26.4\",\n",
        "    \"protobuf==4.25.3\",\n",
        "    \"mediapipe==0.10.21\",\n",
        "    \"opencv-python-headless==4.8.1.78\",\n",
        "    \"scikit-learn==1.3.2\",\n",
        "    \"matplotlib\"\n",
        "]\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "command = [sys.executable, \"-m\", \"pip\", \"install\"] + packages\n",
        "subprocess.check_call(command)\n",
        "\n",
        "print(\"\\nInstallation complete.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# forcing runtime restart\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtvaPtbp6K2",
        "outputId": "7e95abbe-e892-4725-a4b9-c2567d85f885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Verifying installations...\")\n",
        "print(f\"  Python version: {sys.version.split()[0]}\")\n",
        "print(f\"  TensorFlow: {tf.__version__}\")\n",
        "print(f\"  MediaPipe: {mp.__version__}\")\n",
        "print(f\"  OpenCV: {cv2.__version__}\")\n",
        "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"  NumPy: {np.__version__}\") # Should be 1.26.4\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3lpZ6Hmp-kV",
        "outputId": "12b49b91-8766-49b9-ff85-94baad81ba9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Verifying installations...\n",
            "  Python version: 3.12.12\n",
            "  TensorFlow: 2.19.0\n",
            "  MediaPipe: 0.10.21\n",
            "  OpenCV: 4.11.0\n",
            "  Scikit-learn: 1.3.2\n",
            "  NumPy: 1.26.4\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "-ziLyOq5qPs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all required libraries\n",
        "print(\"Importing libraries...\")\n",
        "\n",
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "from typing import List, Sequence\n",
        "\n",
        "# Third-party imports\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"OpenCV imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"OpenCV import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import mediapipe as mp\n",
        "    from mediapipe.tasks import python as mp_python\n",
        "    from mediapipe.tasks.python import vision\n",
        "    print(\"MediaPipe imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"MediaPipe import failed: {e}\")\n",
        "    print(\"  Run the installation cell again.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    print(\"NumPy imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"NumPy import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    print(\"TensorFlow/Keras imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"TensorFlow import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    print(\"Scikit-learn imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"Scikit-learn import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Constants\n",
        "NUM_HANDS = 2\n",
        "NUM_LANDMARKS = 21\n",
        "COORDS = 3\n",
        "FEATURE_VECTOR_LEN = NUM_HANDS * NUM_LANDMARKS * COORDS\n",
        "WRIST_IDX = 0\n",
        "MIDDLE_MCP_IDX = 9\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD0ahNECprYu",
        "outputId": "883ceae5-e8ec-49b9-d705-bb57e31948ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing libraries...\n",
            "OpenCV imported\n",
            "MediaPipe imported\n",
            "NumPy imported\n",
            "TensorFlow/Keras imported\n",
            "Scikit-learn imported\n",
            "\n",
            "============================================================\n",
            "All libraries imported successfully!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive"
      ],
      "metadata": {
        "id": "KDG0CTSqsPjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Google Drive mounted successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f-2ifLpsQNQ",
        "outputId": "120a45fa-8b91-4a22-b232-4f19448ee9f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration"
      ],
      "metadata": {
        "id": "MvE8q_igqiHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WLASL_JSON_PATH = \"/content/wlasl_data/WLASL_v0.3.json\"\n",
        "VIDEO_ROOT = \"/content/wlasl_data/videos\"\n",
        "\n",
        "# File paths\n",
        "NPZ_PATH = \"/content/drive/MyDrive/WLASL Dataset/wlasl_landmarks.npz\"\n",
        "LABELS_OUTPUT = \"wlasl_labels.npy\"\n",
        "MODEL_OUTPUT = \"wlasl_sequence_model.keras\"\n",
        "\n",
        "# Processing parameters\n",
        "SEQUENCE_LENGTH = 32  # Fixed number of frames per sequence\n",
        "FRAME_STRIDE = 2      # Sample every Nth frame\n",
        "MIN_FRAMES = 8        # Discard sequences shorter than this\n",
        "\n",
        "# Training parameters\n",
        "MIN_VIDEOS_PER_GLOSS = 5      # Minimum number of instances needed for gloss to be used\n",
        "MAX_GLOSSES = 25              # Number of glosses if SELECTED_GLOSSES is None\n",
        "MAX_SAMPLES_PER_GLOSS = None  # Limit samples per gloss (None = no limit)\n",
        "TEST_SIZE = 0.2\n",
        "EPOCHS = 80\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "LSTM_UNITS = [128, 64]\n",
        "DENSE_UNITS = 64\n",
        "DROPOUT = 0.5\n",
        "PATIENCE = 10                 # Early stopping patience\n",
        "\n",
        "print(\"Configuration loaded\")\n",
        "print(f\"\\nLooking for:\")\n",
        "print(f\"  JSON: {WLASL_JSON_PATH}\")\n",
        "print(f\"  Videos: {VIDEO_ROOT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnFHNAXcqkYK",
        "outputId": "5ad4e7d2-748e-41da-dd2b-dd054115a423"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded\n",
            "\n",
            "Looking for:\n",
            "  JSON: /content/wlasl_data/WLASL_v0.3.json\n",
            "  Videos: /content/wlasl_data/videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build LSTM Model"
      ],
      "metadata": {
        "id": "e1Zb40HFpEbv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO3dE4xLo9F8",
        "outputId": "f3dd0e44-e9dc-4631-ee3a-68499bbc0d1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model builder function defined\n"
          ]
        }
      ],
      "source": [
        "def build_model(\n",
        "    input_shape: tuple,\n",
        "    num_classes: int,\n",
        "    lstm_units: list,\n",
        "    dense_units: int,\n",
        "    dropout: float,\n",
        "    learning_rate: float,\n",
        ") -> keras.Model:\n",
        "    \"\"\"\n",
        "    Build LSTM model for sequence classification.\n",
        "\n",
        "    Architecture:\n",
        "    - Masking layer (ignores padded zeros)\n",
        "    - LSTM layer 1 (with return_sequences=True)\n",
        "    - Dropout\n",
        "    - LSTM layer 2\n",
        "    - Dropout\n",
        "    - Dense layer (ReLU)\n",
        "    - Output layer (Softmax)\n",
        "    \"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Masking(mask_value=0.0),  # Ignore padded frames\n",
        "        layers.LSTM(lstm_units[0], return_sequences=True, use_cudnn=False), # Disable cuDNN\n",
        "        layers.Dropout(dropout),\n",
        "        layers.LSTM(lstm_units[1], use_cudnn=False), # Disable cuDNN\n",
        "        layers.Dropout(dropout),\n",
        "        layers.Dense(dense_units, activation=\"relu\"),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Model builder function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ],
      "metadata": {
        "id": "neuXidCopIdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "keras.utils.set_random_seed(42)\n",
        "try:\n",
        "    tf.config.experimental.enable_op_determinism()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "\n",
        "data = np.load(NPZ_PATH)\n",
        "sequences = data[\"sequences\"].astype(np.float32)\n",
        "labels = data[\"labels\"]\n",
        "\n",
        "print(f\"Loaded {sequences.shape[0]} sequences\")\n",
        "print(f\"  Shape: {sequences.shape}\")\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "np.save(LABELS_OUTPUT, label_encoder.classes_)\n",
        "print(f\"Saved label order to {LABELS_OUTPUT} ({len(label_encoder.classes_)} classes)\")\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    sequences,\n",
        "    encoded_labels,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=42,\n",
        "    stratify=encoded_labels,\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain samples: {X_train.shape[0]}\")\n",
        "print(f\"Test samples: {X_test.shape[0]}\")\n",
        "\n",
        "# Build model\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"\\nBuilding model...\")\n",
        "print(f\"  Input shape: {input_shape}\")\n",
        "print(f\"  Number of classes: {num_classes}\")\n",
        "\n",
        "model = build_model(\n",
        "    input_shape=input_shape,\n",
        "    num_classes=num_classes,\n",
        "    lstm_units=LSTM_UNITS,\n",
        "    dense_units=DENSE_UNITS,\n",
        "    dropout=DROPOUT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Setup callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        MODEL_OUTPUT,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Train model\n",
        "print(f\"\\nStarting training for up to {EPOCHS} epochs...\")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "bHLp8EdbpCEs",
        "outputId": "f08c6634-6b67-45a2-a473-d3d1ac978aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading preprocessed data...\n",
            "Loaded 10240 sequences\n",
            "  Shape: (10240, 32, 126)\n",
            "Saved label order to wlasl_labels.npy (1575 classes)\n",
            "\n",
            "Train samples: 8192\n",
            "Test samples: 2048\n",
            "\n",
            "Building model...\n",
            "  Input shape: (32, 126)\n",
            "  Number of classes: 1575\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m126\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m130,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1575\u001b[0m)           │       \u001b[38;5;34m102,375\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">130,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1575</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,375</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m286,503\u001b[0m (1.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286,503</span> (1.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m286,503\u001b[0m (1.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">286,503</span> (1.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training for up to 80 epochs...\n",
            "Epoch 1/80\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 8.9022e-04 - loss: 7.3501\n",
            "Epoch 1: val_accuracy improved from -inf to 0.00000, saving model to wlasl_sequence_model.keras\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - accuracy: 8.9165e-04 - loss: 7.3499 - val_accuracy: 0.0000e+00 - val_loss: 7.1354\n",
            "Epoch 2/80\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.0042 - loss: 6.6763\n",
            "Epoch 2: val_accuracy improved from 0.00000 to 0.00610, saving model to wlasl_sequence_model.keras\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 108ms/step - accuracy: 0.0042 - loss: 6.6765 - val_accuracy: 0.0061 - val_loss: 6.9232\n",
            "Epoch 3/80\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.0065 - loss: 6.3509\n",
            "Epoch 3: val_accuracy did not improve from 0.00610\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.0065 - loss: 6.3512 - val_accuracy: 0.0049 - val_loss: 6.8140\n",
            "Epoch 4/80\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0069 - loss: 6.1566\n",
            "Epoch 4: val_accuracy improved from 0.00610 to 0.01220, saving model to wlasl_sequence_model.keras\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.0069 - loss: 6.1568 - val_accuracy: 0.0122 - val_loss: 6.6828\n",
            "Epoch 5/80\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.0107 - loss: 5.9859\n",
            "Epoch 5: val_accuracy improved from 0.01220 to 0.01585, saving model to wlasl_sequence_model.keras\n",
            "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - accuracy: 0.0108 - loss: 5.9860 - val_accuracy: 0.0159 - val_loss: 6.6453\n",
            "Epoch 6/80\n",
            "\u001b[1m  3/231\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.0000e+00 - loss: 6.0301 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate Model Performance"
      ],
      "metadata": {
        "id": "2xhoiIRvpKp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "print(\"Generating predictions on test set...\")\n",
        "predictions = model.predict(X_test, verbose=0)\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"TEST ACCURACY: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"=\"*60)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "# Save final model (ensure it's saved even if early stopping didn't trigger)\n",
        "model.save(MODEL_OUTPUT)\n",
        "print(f\"\\nModel saved to {MODEL_OUTPUT}\")\n",
        "print(f\"Labels saved to {LABELS_OUTPUT}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTo use this model:\")\n",
        "print(f\"1. Download '{MODEL_OUTPUT}' and '{LABELS_OUTPUT}'\")\n",
        "print(f\"2. Load them in your inference script\")\n",
        "print(f\"3. Process videos the same way (landmarks -> normalize -> predict)\")"
      ],
      "metadata": {
        "id": "eJre9owTpNma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Training History"
      ],
      "metadata": {
        "id": "l2P-61Y4pSOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "poZ6GXfIpS7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}