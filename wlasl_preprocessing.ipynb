{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6012c777",
      "metadata": {
        "id": "6012c777"
      },
      "source": [
        "# WLASL Preprocessing\n",
        "\n",
        "The Word-Level American Sign Language (WLASL) dataset consists of approximately 12,000 videos of around 2,000 common words.\n",
        "\n",
        "For preprocessing this dataset, we use MediaPipe for hand landmark extraction from videos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-Up"
      ],
      "metadata": {
        "id": "WxVa0kNromWj"
      },
      "id": "WxVa0kNromWj"
    },
    {
      "cell_type": "markdown",
      "id": "d01425fa",
      "metadata": {
        "id": "d01425fa"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "packages = [\n",
        "    \"numpy==1.26.4\",\n",
        "    \"protobuf==4.25.3\",\n",
        "    \"mediapipe==0.10.21\",\n",
        "    \"opencv-python-headless==4.8.1.78\",\n",
        "    \"scikit-learn==1.3.2\",\n",
        "    \"matplotlib\"\n",
        "]\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "command = [sys.executable, \"-m\", \"pip\", \"install\"] + packages\n",
        "subprocess.check_call(command)\n",
        "\n",
        "print(\"\\nInstallation complete.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# forcing runtime restart\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygqp0lNPOPQu",
        "outputId": "dff65f26-cc05-4871-ffb3-e4f2b3afd47c"
      },
      "id": "ygqp0lNPOPQu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Verifying installations...\")\n",
        "print(f\"  Python version: {sys.version.split()[0]}\")\n",
        "print(f\"  TensorFlow: {tf.__version__}\")\n",
        "print(f\"  MediaPipe: {mp.__version__}\")\n",
        "print(f\"  OpenCV: {cv2.__version__}\")\n",
        "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"  NumPy: {np.__version__}\") # Should be 1.26.4\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKQ4rw_TOaob",
        "outputId": "9930f1ab-0b7d-4d6c-f08c-24eead4f4feb"
      },
      "id": "BKQ4rw_TOaob",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Verifying installations...\n",
            "  Python version: 3.12.12\n",
            "  TensorFlow: 2.19.0\n",
            "  MediaPipe: 0.10.21\n",
            "  OpenCV: 4.8.1\n",
            "  Scikit-learn: 1.3.2\n",
            "  NumPy: 1.26.4\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1f0cc823",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f0cc823",
        "outputId": "502a6666-e0af-42a1-8f00-0dfc0179788a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MediaPipe Hand Landmarker model...\n",
            "Model downloaded to hand_landmarker.task\n"
          ]
        }
      ],
      "source": [
        "# Download MediaPipe Hand Landmarker model\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "model_url = \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\"\n",
        "model_path = \"hand_landmarker.task\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading MediaPipe Hand Landmarker model...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(model_url, model_path)\n",
        "        print(f\"Model downloaded to {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading model: {e}\")\n",
        "        print(\"Trying alternative download method...\")\n",
        "        !wget -q {model_url} -O {model_path}\n",
        "        print(f\"Model downloaded to {model_path}\")\n",
        "else:\n",
        "    print(f\"Model already exists at {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c52db34d",
      "metadata": {
        "id": "c52db34d"
      },
      "source": [
        "### Mount Google Drive and Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e4455cd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4455cd4",
        "outputId": "03e4d195-ffe6-4105-a1e9-26a0c65a92db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5b17f9a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b17f9a5",
        "outputId": "f047e505-5778-4d91-a54f-ef34482aac99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found dataset at: /content/drive/MyDrive/WLASL Dataset/archive.zip\n",
            "\n",
            "Extracting dataset to /content/wlasl_data...\n",
            "Dataset extracted successfully!\n",
            "\n",
            "Dataset structure:\n",
            "wlasl_data/\n",
            "  nslt_2000.json\n",
            "  nslt_1000.json\n",
            "  WLASL_v0.3.json\n",
            "  missing.txt\n",
            "  nslt_300.json\n",
            "  ... and 2 more files\n",
            "  videos/\n",
            "    20235.mp4\n",
            "    08890.mp4\n",
            "    65111.mp4\n",
            "    34832.mp4\n",
            "    26012.mp4\n",
            "    ... and 11975 more files\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to your dataset in Google Drive\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/WLASL Dataset/archive.zip\"\n",
        "EXTRACT_PATH = \"/content/wlasl_data\"\n",
        "\n",
        "# Check if the zip file exists\n",
        "if not os.path.exists(DRIVE_ZIP_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset not found at: {DRIVE_ZIP_PATH}\\n\"\n",
        "                          f\"Please ensure 'archive.zip' is in 'WLASL Dataset' folder in your Google Drive.\")\n",
        "\n",
        "print(f\"Found dataset at: {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "# Extract the dataset\n",
        "print(f\"\\nExtracting dataset to {EXTRACT_PATH}...\")\n",
        "os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_PATH)\n",
        "\n",
        "print(\"Dataset extracted successfully!\")\n",
        "\n",
        "# List the contents to understand the structure\n",
        "print(\"\\nDataset structure:\")\n",
        "for root, dirs, files in os.walk(EXTRACT_PATH):\n",
        "    level = root.replace(EXTRACT_PATH, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    sub_indent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files in each directory\n",
        "        print(f'{sub_indent}{file}')\n",
        "    if len(files) > 5:\n",
        "        print(f'{sub_indent}... and {len(files) - 5} more files')\n",
        "    if level > 2:  # Limit depth to avoid too much output\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0071c40",
      "metadata": {
        "id": "b0071c40"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "960acfb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "960acfb0",
        "outputId": "e6aa4c91-2a5d-4fa9-9043-bba0d2c36cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded\n",
            "\n",
            "Looking for:\n",
            "  JSON: /content/wlasl_data/WLASL_v0.3.json\n",
            "  Videos: /content/wlasl_data/videos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "WLASL_JSON_PATH = \"/content/wlasl_data/WLASL_v0.3.json\"\n",
        "VIDEO_ROOT = \"/content/wlasl_data/videos\"\n",
        "\n",
        "# Output paths\n",
        "OUTPUT_NPZ = \"wlasl_landmarks.npz\"\n",
        "MODEL_OUTPUT = \"wlasl_sequence_model.keras\"\n",
        "LABELS_OUTPUT = \"wlasl_labels.npy\"\n",
        "\n",
        "# Processing parameters\n",
        "SEQUENCE_LENGTH = 32  # Fixed number of frames per sequence\n",
        "FRAME_STRIDE = 2      # Sample every Nth frame\n",
        "MIN_FRAMES = 8        # Discard sequences shorter than this\n",
        "\n",
        "# Glosses to train on (words/signs)\n",
        "# SELECTED_GLOSSES = [\n",
        "#     \"book\", \"drink\", \"computer\", \"before\", \"chair\", \"go\", \"clothes\",\n",
        "#     \"who\", \"candy\", \"cousin\", \"deaf\", \"fine\", \"help\", \"no\", \"orange\",\n",
        "#     \"pizza\", \"please\", \"restaurant\", \"store\", \"thanksgiving\", \"thin\",\n",
        "#     \"walk\", \"year\", \"yes\", \"all\"\n",
        "# ]\n",
        "\n",
        "# Training parameters\n",
        "MIN_VIDEOS_PER_GLOSS = 5      # Minimum number of instances needed for gloss to be used\n",
        "MAX_GLOSSES = 25              # Number of glosses if SELECTED_GLOSSES is None\n",
        "MAX_SAMPLES_PER_GLOSS = None  # Limit samples per gloss (None = no limit)\n",
        "TEST_SIZE = 0.2\n",
        "EPOCHS = 80\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 1e-3\n",
        "LSTM_UNITS = [128, 64]\n",
        "DENSE_UNITS = 64\n",
        "DROPOUT = 0.5\n",
        "PATIENCE = 10                 # Early stopping patience\n",
        "\n",
        "print(\"Configuration loaded\")\n",
        "print(f\"\\nLooking for:\")\n",
        "print(f\"  JSON: {WLASL_JSON_PATH}\")\n",
        "print(f\"  Videos: {VIDEO_ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5762608a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5762608a",
        "outputId": "47ede29b-5696-437d-bb72-1f98436b78d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying dataset paths...\n",
            "\n",
            "JSON file found: /content/wlasl_data/WLASL_v0.3.json\n",
            "  Size: 11.38 MB\n",
            "\n",
            "Video directory found: /content/wlasl_data/videos\n",
            "  Number of video files: 11980\n",
            "  Sample videos: ['20235.mp4', '08890.mp4', '65111.mp4']\n",
            "\n",
            "============================================================\n",
            "All paths verified! You can proceed to the next steps.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Verify that the paths exist\n",
        "import os\n",
        "\n",
        "print(\"Verifying dataset paths...\\n\")\n",
        "\n",
        "# Check JSON file\n",
        "if os.path.exists(WLASL_JSON_PATH):\n",
        "    print(f\"JSON file found: {WLASL_JSON_PATH}\")\n",
        "    file_size = os.path.getsize(WLASL_JSON_PATH) / (1024 * 1024)\n",
        "    print(f\"  Size: {file_size:.2f} MB\")\n",
        "else:\n",
        "    print(f\"JSON file NOT found at: {WLASL_JSON_PATH}\")\n",
        "    print(\"\\nSearching for JSON files in extracted directory...\")\n",
        "    for root, dirs, files in os.walk(\"/content/wlasl_data\"):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                full_path = os.path.join(root, file)\n",
        "                print(f\"  Found: {full_path}\")\n",
        "    print(\"\\nUpdate WLASL_JSON_PATH in the configuration cell above with the correct path\")\n",
        "\n",
        "# Check video directory\n",
        "print()\n",
        "if os.path.exists(VIDEO_ROOT):\n",
        "    print(f\"Video directory found: {VIDEO_ROOT}\")\n",
        "    video_files = [f for f in os.listdir(VIDEO_ROOT) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "    print(f\"  Number of video files: {len(video_files)}\")\n",
        "    if video_files:\n",
        "        print(f\"  Sample videos: {video_files[:3]}\")\n",
        "else:\n",
        "    print(f\"Video directory NOT found at: {VIDEO_ROOT}\")\n",
        "    print(\"\\nSearching for video directories...\")\n",
        "    for root, dirs, files in os.walk(\"/content/wlasl_data\"):\n",
        "        video_files = [f for f in files if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "        if video_files:\n",
        "            print(f\"  Found {len(video_files)} videos in: {root}\")\n",
        "            break\n",
        "    print(\"\\nUpdate VIDEO_ROOT in the configuration cell above with the correct path\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if os.path.exists(WLASL_JSON_PATH) and os.path.exists(VIDEO_ROOT):\n",
        "    print(\"All paths verified! You can proceed to the next steps.\")\n",
        "else:\n",
        "    print(\"Please update the configuration paths based on the information above.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee32e640",
      "metadata": {
        "id": "ee32e640"
      },
      "source": [
        "### Import Libraries and Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "61d0149d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61d0149d",
        "outputId": "8ba2c23e-a8ec-45ea-b814-9fc4641a9ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing libraries...\n",
            "OpenCV imported\n",
            "MediaPipe imported\n",
            "NumPy imported\n",
            "TensorFlow/Keras imported\n",
            "Scikit-learn imported\n",
            "\n",
            "============================================================\n",
            "All libraries imported successfully!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "print(\"Importing libraries...\")\n",
        "\n",
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from collections import Counter\n",
        "from typing import List, Sequence\n",
        "\n",
        "# Third-party imports\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"OpenCV imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"OpenCV import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import mediapipe as mp\n",
        "    from mediapipe.tasks import python as mp_python\n",
        "    from mediapipe.tasks.python import vision\n",
        "    print(\"MediaPipe imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"MediaPipe import failed: {e}\")\n",
        "    print(\"  Run the installation cell again.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "    print(\"NumPy imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"NumPy import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    print(\"TensorFlow/Keras imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"TensorFlow import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    print(\"Scikit-learn imported\")\n",
        "except ImportError as e:\n",
        "    print(f\"Scikit-learn import failed: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Constants\n",
        "NUM_HANDS = 2\n",
        "NUM_LANDMARKS = 21\n",
        "COORDS = 3\n",
        "FEATURE_VECTOR_LEN = NUM_HANDS * NUM_LANDMARKS * COORDS\n",
        "WRIST_IDX = 0\n",
        "MIDDLE_MCP_IDX = 9\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f460f6e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f460f6e5",
        "outputId": "462ed548-a6c1-4128-fb84-adfbf4dc281e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalization function defined\n"
          ]
        }
      ],
      "source": [
        "# Normalization utility function (from preprocessing_utils.py)\n",
        "def normalize_per_hand(X_arr: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Normalize landmarks per hand: translate by wrist, scale by wrist->middle_mcp distance.\n",
        "    This ensures consistent spatial representation regardless of hand position/size in frame.\n",
        "    \"\"\"\n",
        "    Xn = X_arr.copy()\n",
        "    if Xn.ndim == 1:\n",
        "        Xn = Xn.reshape(1, -1)\n",
        "    Xn = Xn.reshape(-1, NUM_HANDS, NUM_LANDMARKS, COORDS)\n",
        "\n",
        "    for i in range(Xn.shape[0]):\n",
        "        for h in range(NUM_HANDS):\n",
        "            hand = Xn[i, h]\n",
        "            # Skip if hand is all zeros (no detection)\n",
        "            if np.allclose(hand, 0.0):\n",
        "                continue\n",
        "\n",
        "            # Translate: center on wrist\n",
        "            wrist = hand[WRIST_IDX]\n",
        "            hand[:, :2] -= wrist[:2]  # translate x,y; keep z as-is\n",
        "\n",
        "            # Scale: normalize by wrist->middle_mcp distance on xy plane\n",
        "            ref = hand[MIDDLE_MCP_IDX]\n",
        "            scale = np.linalg.norm(ref[:2])\n",
        "            if scale > 1e-6:\n",
        "                hand[:, :2] /= scale\n",
        "\n",
        "            Xn[i, h] = hand\n",
        "\n",
        "    return Xn.reshape(-1, FEATURE_VECTOR_LEN)\n",
        "\n",
        "print(\"Normalization function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "VRvy8NCvosO2"
      },
      "id": "VRvy8NCvosO2"
    },
    {
      "cell_type": "markdown",
      "id": "3044e50b",
      "metadata": {
        "id": "3044e50b"
      },
      "source": [
        "### Define Preprocessing Functions\n",
        "\n",
        "These functions handle:\n",
        "- Loading WLASL metadata\n",
        "- Selecting glosses (words) to train on\n",
        "- Building MediaPipe hand detector\n",
        "- Extracting landmarks from video frames\n",
        "- Processing videos into fixed-length sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e754870c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e754870c",
        "outputId": "9f6e8793-b089-43cd-f12e-0c21b7ab979a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing functions defined\n"
          ]
        }
      ],
      "source": [
        "def load_metadata(meta_path: str) -> Sequence[dict]:\n",
        "    \"\"\"Load WLASL JSON metadata file.\"\"\"\n",
        "    with open(meta_path, \"r\", encoding=\"utf-8\") as handle:\n",
        "        return json.load(handle)\n",
        "\n",
        "\n",
        "def choose_glosses(metadata: Sequence[dict], selected_glosses: List[str] = None, max_glosses: int = 25) -> List[str]:\n",
        "    \"\"\"\n",
        "    Select which glosses (words) to include in training.\n",
        "    If selected_glosses is provided, use those. Otherwise, pick most frequent ones.\n",
        "    \"\"\"\n",
        "    if selected_glosses:\n",
        "        return selected_glosses\n",
        "\n",
        "    # Count samples per gloss\n",
        "    counts = Counter()\n",
        "    for entry in metadata:\n",
        "        gloss = entry.get(\"gloss\")\n",
        "        if not gloss:\n",
        "            continue\n",
        "        counts[gloss] += len(entry.get(\"instances\", []))\n",
        "\n",
        "    # Return most common glosses\n",
        "    most_common = [gloss for gloss, _ in counts.most_common(max_glosses)]\n",
        "    return most_common\n",
        "\n",
        "\n",
        "def build_detector(task_path: str) -> vision.HandLandmarker:\n",
        "    \"\"\"Initialize MediaPipe hand landmarker.\"\"\"\n",
        "    if not os.path.exists(task_path):\n",
        "        raise FileNotFoundError(f\"MediaPipe model not found at '{task_path}'\")\n",
        "\n",
        "    base_options = mp_python.BaseOptions(model_asset_path=task_path)\n",
        "    options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
        "    return vision.HandLandmarker.create_from_options(options)\n",
        "\n",
        "\n",
        "def extract_landmarks(detector: vision.HandLandmarker, frame_rgb: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extract hand landmarks from a single frame.\n",
        "    Returns normalized feature vector of shape (126,) = 2 hands × 21 landmarks × 3 coords (x,y,z)\n",
        "    \"\"\"\n",
        "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "    result = detector.detect(mp_image)\n",
        "\n",
        "    landmarks = []\n",
        "    if result.hand_landmarks:\n",
        "        for hand_landmarks in result.hand_landmarks:\n",
        "            for lm in hand_landmarks:\n",
        "                landmarks.extend([lm.x, lm.y, lm.z])\n",
        "\n",
        "    # Pad with zeros if less than 2 hands detected\n",
        "    if len(landmarks) < FEATURE_VECTOR_LEN:\n",
        "        landmarks.extend([0.0] * (FEATURE_VECTOR_LEN - len(landmarks)))\n",
        "\n",
        "    arr = np.asarray(landmarks, dtype=np.float32).reshape(1, -1)\n",
        "\n",
        "    # Apply normalization\n",
        "    try:\n",
        "        arr = normalize_per_hand(arr)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return arr.astype(np.float32)\n",
        "\n",
        "\n",
        "def process_video(\n",
        "    detector: vision.HandLandmarker,\n",
        "    video_path: str,\n",
        "    frame_start: int,\n",
        "    frame_end: int,\n",
        "    sequence_length: int,\n",
        "    frame_stride: int,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Process a video file and extract a fixed-length sequence of landmark frames.\n",
        "\n",
        "    Args:\n",
        "        detector: MediaPipe hand landmarker\n",
        "        video_path: Path to video file\n",
        "        frame_start: Starting frame index (from metadata)\n",
        "        frame_end: Ending frame index (from metadata)\n",
        "        sequence_length: Target number of frames in output\n",
        "        frame_stride: Sample every Nth frame\n",
        "\n",
        "    Returns:\n",
        "        Array of shape (sequence_length, FEATURE_VECTOR_LEN)\n",
        "    \"\"\"\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "    if not capture.isOpened():\n",
        "        raise RuntimeError(f\"Could not open video '{video_path}'\")\n",
        "\n",
        "    total_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    start = max(0, frame_start or 0)\n",
        "    end = frame_end if frame_end else total_frames\n",
        "    end = min(end, total_frames)\n",
        "    if end <= start:\n",
        "        end = total_frames\n",
        "\n",
        "    capture.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "\n",
        "    sampled = []\n",
        "    frame_index = start\n",
        "\n",
        "    while frame_index < end:\n",
        "        success, frame_bgr = capture.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Sample every frame_stride frames\n",
        "        if (frame_index - start) % frame_stride == 0:\n",
        "            frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "            sampled.append(extract_landmarks(detector, frame_rgb).reshape(-1))\n",
        "\n",
        "        frame_index += 1\n",
        "\n",
        "        # Stop if we have enough frames\n",
        "        if len(sampled) >= sequence_length:\n",
        "            break\n",
        "\n",
        "    capture.release()\n",
        "\n",
        "    if not sampled:\n",
        "        return np.empty((0, FEATURE_VECTOR_LEN), dtype=np.float32)\n",
        "\n",
        "    sequence = np.stack(sampled).astype(np.float32)\n",
        "\n",
        "    # Truncate if too long\n",
        "    if sequence.shape[0] >= sequence_length:\n",
        "        return sequence[:sequence_length]\n",
        "\n",
        "    # Pad with zeros if too short\n",
        "    padding = np.zeros((sequence_length - sequence.shape[0], FEATURE_VECTOR_LEN), dtype=np.float32)\n",
        "    return np.vstack((sequence, padding))\n",
        "\n",
        "print(\"Preprocessing functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ac8cfa",
      "metadata": {
        "id": "a5ac8cfa"
      },
      "source": [
        "### Run Preprocessing\n",
        "\n",
        "In this section:\n",
        "1. Load WLASL metadata\n",
        "2. Select glosses to train on\n",
        "3. Process each video to extract landmarks\n",
        "4. Save results to `wlasl_landmarks.npz`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata\n",
        "print(\"Loading WLASL metadata...\")\n",
        "metadata = load_metadata(WLASL_JSON_PATH)\n",
        "print(f\"Loaded {len(metadata)} entries from metadata\")\n",
        "\n",
        "# Scanning glosses\n",
        "print(f\"\\nScanning disk for glosses with >= {MIN_VIDEOS_PER_GLOSS} videos...\")\n",
        "\n",
        "gloss_file_counts = Counter()\n",
        "valid_video_ids = set()\n",
        "\n",
        "# Iterate through metadata to check file existence\n",
        "for entry in metadata:\n",
        "    gloss = entry.get(\"gloss\")\n",
        "    if not gloss: continue\n",
        "\n",
        "    for instance in entry.get(\"instances\", []):\n",
        "        video_id = instance.get(\"video_id\")\n",
        "        if not video_id: continue\n",
        "\n",
        "        # Check existence\n",
        "        video_path = os.path.join(VIDEO_ROOT, f\"{video_id}.mp4\")\n",
        "        if os.path.exists(video_path):\n",
        "            gloss_file_counts[gloss] += 1\n",
        "            valid_video_ids.add(video_id)\n",
        "\n",
        "# Create the final list of glosses to process\n",
        "glosses_to_keep = [g for g, c in gloss_file_counts.items() if c >= MIN_VIDEOS_PER_GLOSS]\n",
        "gloss_set = set(glosses_to_keep)\n",
        "\n",
        "print(f\"Scan complete.\")\n",
        "print(f\"  Total unique glosses in metadata: {len(gloss_file_counts)}\")\n",
        "print(f\"  Glosses with >= {MIN_VIDEOS_PER_GLOSS} videos: {len(glosses_to_keep)}\")\n",
        "print(f\"  Glosses dropped (too few videos): {len(gloss_file_counts) - len(glosses_to_keep)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoU7uI93cg-6",
        "outputId": "62fae836-0ecb-4d32-d148-b38be2bfc0f9"
      },
      "id": "qoU7uI93cg-6",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading WLASL metadata...\n",
            "Loaded 2000 entries from metadata\n",
            "\n",
            "Scanning disk for glosses with >= 5 videos...\n",
            "Scan complete.\n",
            "  Total unique glosses in metadata: 2000\n",
            "  Glosses with >= 5 videos: 1575\n",
            "  Glosses dropped (too few videos): 425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "22f57dc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22f57dc3",
        "outputId": "92a87284-ad58-4b12-cfb1-08c00ef3d2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing MediaPipe hand detector...\n",
            "Detector ready\n",
            "\n",
            "Processing videos...\n",
            "  Processed 50 videos...\n",
            "  Processed 100 videos...\n",
            "  Processed 150 videos...\n",
            "  Processed 200 videos...\n",
            "  Processed 250 videos...\n",
            "  Processed 300 videos...\n",
            "  Processed 350 videos...\n",
            "  Processed 400 videos...\n",
            "  Processed 450 videos...\n",
            "  Processed 500 videos...\n",
            "  Processed 550 videos...\n",
            "  Processed 600 videos...\n",
            "  Processed 650 videos...\n",
            "  Processed 700 videos...\n",
            "  Processed 750 videos...\n",
            "  Processed 800 videos...\n",
            "  Processed 850 videos...\n",
            "  Processed 900 videos...\n",
            "  Processed 950 videos...\n",
            "  Processed 1000 videos...\n",
            "  Processed 1050 videos...\n",
            "  Processed 1100 videos...\n",
            "  Processed 1150 videos...\n",
            "  Processed 1200 videos...\n",
            "  Processed 1250 videos...\n",
            "  Processed 1300 videos...\n",
            "  Processed 1350 videos...\n",
            "  Processed 1400 videos...\n",
            "  Processed 1450 videos...\n",
            "  Processed 1500 videos...\n",
            "  Processed 1550 videos...\n",
            "  Processed 1600 videos...\n",
            "  Processed 1650 videos...\n",
            "  Processed 1700 videos...\n",
            "  Processed 1750 videos...\n",
            "  Processed 1800 videos...\n",
            "  Processed 1850 videos...\n",
            "  Processed 1900 videos...\n",
            "  Processed 1950 videos...\n",
            "  Processed 2000 videos...\n",
            "  Processed 2050 videos...\n",
            "  Processed 2100 videos...\n",
            "  Processed 2150 videos...\n",
            "  Processed 2200 videos...\n",
            "  Processed 2250 videos...\n",
            "  Processed 2300 videos...\n",
            "  Processed 2350 videos...\n",
            "  Processed 2400 videos...\n",
            "  Processed 2450 videos...\n",
            "  Processed 2500 videos...\n",
            "  Processed 2550 videos...\n",
            "  Processed 2600 videos...\n",
            "  Processed 2650 videos...\n",
            "  Processed 2700 videos...\n",
            "  Processed 2750 videos...\n",
            "  Processed 2800 videos...\n",
            "  Processed 2850 videos...\n",
            "  Processed 2900 videos...\n",
            "  Processed 2950 videos...\n",
            "  Processed 3000 videos...\n",
            "  Processed 3050 videos...\n",
            "  Processed 3100 videos...\n",
            "  Processed 3150 videos...\n",
            "  Processed 3200 videos...\n",
            "  Processed 3250 videos...\n",
            "  Processed 3300 videos...\n",
            "  Processed 3350 videos...\n",
            "  Processed 3400 videos...\n",
            "  Processed 3450 videos...\n",
            "  Processed 3500 videos...\n",
            "  Processed 3550 videos...\n",
            "  Processed 3600 videos...\n",
            "  Processed 3650 videos...\n",
            "  Processed 3700 videos...\n",
            "  Processed 3750 videos...\n",
            "  Processed 3800 videos...\n",
            "  Processed 3850 videos...\n",
            "  Processed 3900 videos...\n",
            "  Processed 3950 videos...\n",
            "  Processed 4000 videos...\n",
            "  Processed 4050 videos...\n",
            "  Processed 4100 videos...\n",
            "  Processed 4150 videos...\n",
            "  Processed 4200 videos...\n",
            "  Processed 4250 videos...\n",
            "  Processed 4300 videos...\n",
            "  Processed 4350 videos...\n",
            "  Processed 4400 videos...\n",
            "  Processed 4450 videos...\n",
            "  Processed 4500 videos...\n",
            "  Processed 4550 videos...\n",
            "  Processed 4600 videos...\n",
            "  Processed 4650 videos...\n",
            "  Processed 4700 videos...\n",
            "  Processed 4750 videos...\n",
            "  Processed 4800 videos...\n",
            "  Processed 4850 videos...\n",
            "  Processed 4900 videos...\n",
            "  Processed 4950 videos...\n",
            "  Processed 5000 videos...\n",
            "  Processed 5050 videos...\n",
            "  Processed 5100 videos...\n",
            "  Processed 5150 videos...\n",
            "  Processed 5200 videos...\n",
            "  Processed 5250 videos...\n",
            "  Processed 5300 videos...\n",
            "  Processed 5350 videos...\n",
            "  Processed 5400 videos...\n",
            "  Processed 5450 videos...\n",
            "  Processed 5500 videos...\n",
            "  Processed 5550 videos...\n",
            "  Processed 5600 videos...\n",
            "  Processed 5650 videos...\n",
            "  Processed 5700 videos...\n",
            "  Processed 5750 videos...\n",
            "  Processed 5800 videos...\n",
            "  Processed 5850 videos...\n",
            "  Processed 5900 videos...\n",
            "  Processed 5950 videos...\n",
            "  Processed 6000 videos...\n",
            "  Processed 6050 videos...\n",
            "  Processed 6100 videos...\n",
            "  Processed 6150 videos...\n",
            "  Processed 6200 videos...\n",
            "  Processed 6250 videos...\n",
            "  Processed 6300 videos...\n",
            "  Processed 6350 videos...\n",
            "  Processed 6400 videos...\n",
            "  Processed 6450 videos...\n",
            "  Processed 6500 videos...\n",
            "  Processed 6550 videos...\n",
            "  Processed 6600 videos...\n",
            "  Processed 6650 videos...\n",
            "  Processed 6700 videos...\n",
            "  Processed 6750 videos...\n",
            "  Processed 6800 videos...\n",
            "  Processed 6850 videos...\n",
            "  Processed 6900 videos...\n",
            "  Processed 6950 videos...\n",
            "  Processed 7000 videos...\n",
            "  Processed 7050 videos...\n",
            "  Processed 7100 videos...\n",
            "  Processed 7150 videos...\n",
            "  Processed 7200 videos...\n",
            "  Processed 7250 videos...\n",
            "  Processed 7300 videos...\n",
            "  Processed 7350 videos...\n",
            "  Processed 7400 videos...\n",
            "  Processed 7450 videos...\n",
            "  Processed 7500 videos...\n",
            "  Processed 7550 videos...\n",
            "  Processed 7600 videos...\n",
            "  Processed 7650 videos...\n",
            "  Processed 7700 videos...\n",
            "  Processed 7750 videos...\n",
            "  Processed 7800 videos...\n",
            "  Processed 7850 videos...\n",
            "  Processed 7900 videos...\n",
            "  Processed 7950 videos...\n",
            "  Processed 8000 videos...\n",
            "  Processed 8050 videos...\n",
            "  Processed 8100 videos...\n",
            "  Processed 8150 videos...\n",
            "  Processed 8200 videos...\n",
            "  Processed 8250 videos...\n",
            "  Processed 8300 videos...\n",
            "  Processed 8350 videos...\n",
            "  Processed 8400 videos...\n",
            "  Processed 8450 videos...\n",
            "  Processed 8500 videos...\n",
            "  Processed 8550 videos...\n",
            "  Processed 8600 videos...\n",
            "  Processed 8650 videos...\n",
            "  Processed 8700 videos...\n",
            "  Processed 8750 videos...\n",
            "  Processed 8800 videos...\n",
            "  Processed 8850 videos...\n",
            "  Processed 8900 videos...\n",
            "  Processed 8950 videos...\n",
            "  Processed 9000 videos...\n",
            "  Processed 9050 videos...\n",
            "  Processed 9100 videos...\n",
            "  Processed 9150 videos...\n",
            "  Processed 9200 videos...\n",
            "  Processed 9250 videos...\n",
            "  Processed 9300 videos...\n",
            "  Processed 9350 videos...\n",
            "  Processed 9400 videos...\n",
            "  Processed 9450 videos...\n",
            "  Processed 9500 videos...\n",
            "  Processed 9550 videos...\n",
            "  Processed 9600 videos...\n",
            "  Processed 9650 videos...\n",
            "  Processed 9700 videos...\n",
            "  Processed 9750 videos...\n",
            "  Processed 9800 videos...\n",
            "  Processed 9850 videos...\n",
            "  Processed 9900 videos...\n",
            "  Processed 9950 videos...\n",
            "  Processed 10000 videos...\n",
            "  Processed 10050 videos...\n",
            "  Processed 10100 videos...\n",
            "  Processed 10150 videos...\n",
            "  Processed 10200 videos...\n",
            "\n",
            "Processing complete!\n",
            "  Total processed: 10240\n",
            "  Total skipped: 144\n",
            "\n",
            "Saved 10240 samples to wlasl_landmarks.npz\n",
            "  Sequence shape: (10240, 32, 126)\n",
            "\n",
            "  Sample distribution:\n",
            "    a lot: 7\n",
            "    abdomen: 5\n",
            "    able: 5\n",
            "    about: 7\n",
            "    above: 5\n",
            "    accent: 5\n",
            "    accept: 8\n",
            "    accident: 13\n",
            "    accomplish: 5\n",
            "    accountant: 5\n",
            "    across: 6\n",
            "    act: 5\n",
            "    action: 6\n",
            "    active: 5\n",
            "    activity: 5\n",
            "    actor: 6\n",
            "    adapt: 6\n",
            "    add: 9\n",
            "    admire: 5\n",
            "    admit: 5\n",
            "    adopt: 6\n",
            "    adult: 7\n",
            "    affect: 6\n",
            "    afraid: 5\n",
            "    africa: 8\n",
            "    after: 7\n",
            "    afternoon: 7\n",
            "    again: 8\n",
            "    against: 5\n",
            "    age: 7\n",
            "    ago: 9\n",
            "    agree: 5\n",
            "    agreement: 6\n",
            "    aid: 5\n",
            "    aim: 5\n",
            "    airplane: 7\n",
            "    alarm: 5\n",
            "    algebra: 5\n",
            "    all: 8\n",
            "    all day: 5\n",
            "    allergy: 8\n",
            "    alligator: 5\n",
            "    allow: 8\n",
            "    almost: 5\n",
            "    alone: 9\n",
            "    already: 7\n",
            "    also: 7\n",
            "    always: 7\n",
            "    amazing: 5\n",
            "    america: 5\n",
            "    amputate: 5\n",
            "    analyze: 8\n",
            "    and: 5\n",
            "    angel: 7\n",
            "    angle: 6\n",
            "    angry: 7\n",
            "    animal: 9\n",
            "    anniversary: 5\n",
            "    announce: 5\n",
            "    another: 5\n",
            "    answer: 7\n",
            "    any: 5\n",
            "    apart: 5\n",
            "    apartment: 6\n",
            "    apostrophe: 5\n",
            "    appear: 7\n",
            "    appetite: 4\n",
            "    apple: 11\n",
            "    appointment: 10\n",
            "    appreciate: 5\n",
            "    approach: 5\n",
            "    appropriate: 5\n",
            "    approve: 7\n",
            "    april: 5\n",
            "    archery: 5\n",
            "    area: 7\n",
            "    argue: 10\n",
            "    arm: 7\n",
            "    army: 5\n",
            "    around: 5\n",
            "    arrest: 4\n",
            "    arrive: 8\n",
            "    arrogant: 6\n",
            "    art: 7\n",
            "    artist: 5\n",
            "    asia: 7\n",
            "    ask: 7\n",
            "    assist: 5\n",
            "    assistant: 5\n",
            "    attend: 5\n",
            "    attention: 6\n",
            "    attitude: 7\n",
            "    attract: 6\n",
            "    auction: 4\n",
            "    audience: 6\n",
            "    august: 6\n",
            "    aunt: 7\n",
            "    australia: 9\n",
            "    authority: 5\n",
            "    autumn: 7\n",
            "    average: 5\n",
            "    avoid: 7\n",
            "    awake: 5\n",
            "    away: 6\n",
            "    awful: 8\n",
            "    awkward: 7\n",
            "    baby: 8\n",
            "    back: 7\n",
            "    background: 5\n",
            "    backpack: 7\n",
            "    bacon: 7\n",
            "    bad: 10\n",
            "    bake: 7\n",
            "    balance: 10\n",
            "    bald: 6\n",
            "    ball: 9\n",
            "    balloon: 9\n",
            "    banana: 9\n",
            "    baptize: 5\n",
            "    bar: 11\n",
            "    barely: 9\n",
            "    bark: 8\n",
            "    baseball: 6\n",
            "    basement: 6\n",
            "    basketball: 12\n",
            "    bath: 7\n",
            "    bathroom: 7\n",
            "    bear: 7\n",
            "    beard: 9\n",
            "    beautiful: 6\n",
            "    because: 9\n",
            "    become: 5\n",
            "    bed: 13\n",
            "    bedroom: 6\n",
            "    bee: 6\n",
            "    beer: 8\n",
            "    before: 16\n",
            "    beg: 5\n",
            "    beginning: 7\n",
            "    behavior: 5\n",
            "    behind: 5\n",
            "    belief: 7\n",
            "    believe: 7\n",
            "    bell: 6\n",
            "    below: 6\n",
            "    belt: 7\n",
            "    benefit: 7\n",
            "    berry: 5\n",
            "    beside: 5\n",
            "    best: 5\n",
            "    bet: 6\n",
            "    better: 5\n",
            "    between: 6\n",
            "    bicycle: 6\n",
            "    big: 9\n",
            "    biology: 6\n",
            "    bird: 9\n",
            "    birth: 6\n",
            "    birthday: 6\n",
            "    bite: 6\n",
            "    bitter: 8\n",
            "    black: 10\n",
            "    blame: 6\n",
            "    blanket: 9\n",
            "    blend: 5\n",
            "    bless: 6\n",
            "    blind: 8\n",
            "    blood: 5\n",
            "    blow: 5\n",
            "    blue: 8\n",
            "    boat: 8\n",
            "    body: 6\n",
            "    book: 6\n",
            "    bored: 7\n",
            "    borrow: 6\n",
            "    boss: 7\n",
            "    both: 6\n",
            "    bother: 8\n",
            "    bottle: 7\n",
            "    bottom: 8\n",
            "    bowl: 6\n",
            "    bowling: 13\n",
            "    box: 7\n",
            "    boy: 8\n",
            "    boyfriend: 5\n",
            "    bracelet: 7\n",
            "    brag: 6\n",
            "    brave: 5\n",
            "    bread: 7\n",
            "    break: 5\n",
            "    breakfast: 5\n",
            "    breathe: 6\n",
            "    brief: 4\n",
            "    bright: 6\n",
            "    bring: 8\n",
            "    broke: 5\n",
            "    brother: 11\n",
            "    brown: 8\n",
            "    brush: 7\n",
            "    buffalo: 5\n",
            "    build: 6\n",
            "    building: 6\n",
            "    bull: 5\n",
            "    bully: 6\n",
            "    bus: 5\n",
            "    bush: 6\n",
            "    business: 7\n",
            "    busy: 5\n",
            "    but: 6\n",
            "    butter: 6\n",
            "    butterfly: 5\n",
            "    button: 5\n",
            "    buy: 9\n",
            "    bye: 5\n",
            "    cabinet: 5\n",
            "    cafeteria: 8\n",
            "    cake: 8\n",
            "    calculate: 7\n",
            "    calculator: 5\n",
            "    calculus: 5\n",
            "    california: 9\n",
            "    call: 12\n",
            "    calm: 7\n",
            "    camera: 5\n",
            "    camp: 5\n",
            "    camping: 5\n",
            "    can: 9\n",
            "    canada: 7\n",
            "    cancel: 8\n",
            "    candidate: 5\n",
            "    candle: 6\n",
            "    candy: 13\n",
            "    cannot: 6\n",
            "    caption: 7\n",
            "    car: 7\n",
            "    card: 8\n",
            "    care: 7\n",
            "    careful: 9\n",
            "    carnival: 4\n",
            "    carrot: 9\n",
            "    carry: 7\n",
            "    cat: 9\n",
            "    catch: 9\n",
            "    category: 5\n",
            "    catholic: 5\n",
            "    cause: 6\n",
            "    ceiling: 6\n",
            "    celebrate: 6\n",
            "    cemetery: 6\n",
            "    cent: 6\n",
            "    center: 7\n",
            "    cereal: 8\n",
            "    certificate: 6\n",
            "    chain: 7\n",
            "    chair: 7\n",
            "    challenge: 5\n",
            "    champion: 11\n",
            "    chance: 5\n",
            "    change: 12\n",
            "    chapter: 5\n",
            "    character: 7\n",
            "    chase: 6\n",
            "    chat: 9\n",
            "    cheap: 7\n",
            "    cheat: 10\n",
            "    check: 11\n",
            "    cheese: 7\n",
            "    chemical: 5\n",
            "    chemistry: 6\n",
            "    cherry: 5\n",
            "    chicken: 5\n",
            "    child: 9\n",
            "    children: 7\n",
            "    chocolate: 6\n",
            "    choice: 8\n",
            "    choir: 6\n",
            "    choose: 8\n",
            "    chop: 7\n",
            "    christian: 6\n",
            "    christmas: 8\n",
            "    church: 6\n",
            "    cigarette: 4\n",
            "    circle: 5\n",
            "    city: 9\n",
            "    class: 9\n",
            "    classroom: 5\n",
            "    clean: 7\n",
            "    clear: 5\n",
            "    clever: 6\n",
            "    climb: 5\n",
            "    clock: 5\n",
            "    close: 8\n",
            "    closet: 5\n",
            "    clothes: 5\n",
            "    cloud: 8\n",
            "    clown: 5\n",
            "    clueless: 5\n",
            "    clumsy: 4\n",
            "    coach: 6\n",
            "    coat: 5\n",
            "    cochlear implant: 7\n",
            "    coconut: 5\n",
            "    coffee: 7\n",
            "    cold: 12\n",
            "    college: 7\n",
            "    color: 8\n",
            "    comb: 6\n",
            "    come: 6\n",
            "    come here: 6\n",
            "    comfortable: 7\n",
            "    command: 5\n",
            "    comment: 5\n",
            "    committee: 5\n",
            "    common: 5\n",
            "    common sense: 5\n",
            "    community: 6\n",
            "    commute: 5\n",
            "    compare: 7\n",
            "    complain: 6\n",
            "    complete: 5\n",
            "    complex: 7\n",
            "    compromise: 6\n",
            "    computer: 14\n",
            "    concern: 5\n",
            "    conflict: 7\n",
            "    confront: 6\n",
            "    confused: 6\n",
            "    congress: 5\n",
            "    connect: 5\n",
            "    constitution: 6\n",
            "    construct: 5\n",
            "    contact: 7\n",
            "    continue: 6\n",
            "    contribute: 7\n",
            "    control: 5\n",
            "    conversation: 5\n",
            "    convince: 10\n",
            "    cook: 8\n",
            "    cookie: 8\n",
            "    cool: 15\n",
            "    cop: 8\n",
            "    copy: 8\n",
            "    corn: 12\n",
            "    corner: 5\n",
            "    correct: 9\n",
            "    cost: 6\n",
            "    couch: 5\n",
            "    cough: 6\n",
            "    counsel: 5\n",
            "    count: 6\n",
            "    country: 9\n",
            "    cousin: 13\n",
            "    cover: 5\n",
            "    cow: 8\n",
            "    crab: 6\n",
            "    cracker: 6\n",
            "    crash: 9\n",
            "    crave: 4\n",
            "    crazy: 7\n",
            "    cross: 5\n",
            "    cry: 10\n",
            "    cup: 6\n",
            "    curious: 6\n",
            "    curriculum: 6\n",
            "    curse: 6\n",
            "    cut: 8\n",
            "    cute: 7\n",
            "    dad: 7\n",
            "    daily: 5\n",
            "    dance: 7\n",
            "    danger: 5\n",
            "    dangerous: 6\n",
            "    dark: 12\n",
            "    date: 5\n",
            "    daughter: 10\n",
            "    day: 9\n",
            "    dead: 5\n",
            "    deaf: 11\n",
            "    death: 4\n",
            "    december: 5\n",
            "    decide: 9\n",
            "    decorate: 9\n",
            "    decrease: 5\n",
            "    deduct: 6\n",
            "    deep: 8\n",
            "    deer: 7\n",
            "    defend: 5\n",
            "    degree: 6\n",
            "    delay: 11\n",
            "    delicious: 10\n",
            "    demand: 7\n",
            "    demonstrate: 6\n",
            "    dentist: 8\n",
            "    deny: 5\n",
            "    deodorant: 6\n",
            "    depend: 7\n",
            "    deposit: 5\n",
            "    depressed: 5\n",
            "    describe: 7\n",
            "    desert: 7\n",
            "    design: 5\n",
            "    desk: 6\n",
            "    dessert: 8\n",
            "    destroy: 7\n",
            "    develop: 8\n",
            "    diabetes: 5\n",
            "    diamond: 6\n",
            "    diaper: 6\n",
            "    diarrhea: 6\n",
            "    dictionary: 6\n",
            "    different: 7\n",
            "    dig: 5\n",
            "    dime: 5\n",
            "    dining room: 5\n",
            "    dinner: 7\n",
            "    dinosaur: 7\n",
            "    diploma: 5\n",
            "    dirt: 5\n",
            "    dirty: 9\n",
            "    disagree: 5\n",
            "    disappear: 7\n",
            "    discipline: 5\n",
            "    disconnect: 8\n",
            "    discover: 7\n",
            "    discuss: 8\n",
            "    disgust: 6\n",
            "    dissolve: 7\n",
            "    disturb: 5\n",
            "    dive: 9\n",
            "    divide: 6\n",
            "    divorce: 6\n",
            "    doctor: 10\n",
            "    document: 7\n",
            "    dog: 11\n",
            "    doll: 7\n",
            "    dollar: 8\n",
            "    dolphin: 5\n",
            "    don't want: 6\n",
            "    done: 5\n",
            "    door: 7\n",
            "    dorm: 6\n",
            "    dormitory: 5\n",
            "    double: 6\n",
            "    doubt: 6\n",
            "    down: 8\n",
            "    drama: 5\n",
            "    draw: 6\n",
            "    drawer: 7\n",
            "    dream: 6\n",
            "    dress: 7\n",
            "    drink: 15\n",
            "    drive: 7\n",
            "    drop: 9\n",
            "    drum: 5\n",
            "    drunk: 7\n",
            "    dry: 9\n",
            "    duck: 6\n",
            "    due: 6\n",
            "    dull: 6\n",
            "    during: 5\n",
            "    dusk: 5\n",
            "    duty: 5\n",
            "    eagle: 7\n",
            "    ear: 8\n",
            "    early: 6\n",
            "    earn: 6\n",
            "    earring: 6\n",
            "    earth: 5\n",
            "    earthquake: 5\n",
            "    east: 8\n",
            "    easter: 7\n",
            "    easy: 6\n",
            "    eat: 7\n",
            "    economy: 5\n",
            "    educate: 7\n",
            "    education: 5\n",
            "    egg: 7\n",
            "    egypt: 6\n",
            "    eight: 6\n",
            "    eighteen: 6\n",
            "    electrician: 5\n",
            "    electricity: 5\n",
            "    elephant: 7\n",
            "    elevator: 6\n",
            "    email: 6\n",
            "    embarrass: 6\n",
            "    emotion: 6\n",
            "    empty: 5\n",
            "    encourage: 7\n",
            "    end: 6\n",
            "    energy: 5\n",
            "    engage: 5\n",
            "    engine: 5\n",
            "    engineer: 5\n",
            "    england: 5\n",
            "    english: 5\n",
            "    enjoy: 8\n",
            "    enormous: 5\n",
            "    enough: 5\n",
            "    enter: 5\n",
            "    environment: 11\n",
            "    equal: 5\n",
            "    erase: 5\n",
            "    eraser: 5\n",
            "    escape: 8\n",
            "    establish: 5\n",
            "    eternity: 5\n",
            "    europe: 6\n",
            "    evaluate: 5\n",
            "    event: 7\n",
            "    every: 5\n",
            "    every monday: 4\n",
            "    every tuesday: 5\n",
            "    evidence: 7\n",
            "    exact: 6\n",
            "    exaggerate: 5\n",
            "    example: 11\n",
            "    except: 5\n",
            "    exchange: 8\n",
            "    excited: 6\n",
            "    exercise: 5\n",
            "    expect: 6\n",
            "    expensive: 8\n",
            "    experience: 6\n",
            "    experiment: 6\n",
            "    expert: 6\n",
            "    explain: 7\n",
            "    eye: 6\n",
            "    eyes: 4\n",
            "    face: 7\n",
            "    fact: 6\n",
            "    faculty: 5\n",
            "    fail: 6\n",
            "    fake: 6\n",
            "    fall in love: 5\n",
            "    family: 11\n",
            "    famous: 6\n",
            "    fancy: 6\n",
            "    far: 11\n",
            "    farm: 8\n",
            "    fast: 8\n",
            "    fat: 10\n",
            "    father: 7\n",
            "    fault: 9\n",
            "    favorite: 5\n",
            "    fear: 5\n",
            "    feed: 6\n",
            "    feedback: 6\n",
            "    feel: 7\n",
            "    fence: 6\n",
            "    few: 5\n",
            "    fight: 7\n",
            "    final: 5\n",
            "    finally: 7\n",
            "    find: 8\n",
            "    fine: 9\n",
            "    finish: 9\n",
            "    firefighter: 5\n",
            "    first: 9\n",
            "    fish: 10\n",
            "    fishing: 6\n",
            "    five: 5\n",
            "    fix: 6\n",
            "    flag: 6\n",
            "    flexible: 7\n",
            "    flirt: 6\n",
            "    floor: 6\n",
            "    flower: 7\n",
            "    flute: 6\n",
            "    fly: 8\n",
            "    fold: 6\n",
            "    follow: 9\n",
            "    food: 7\n",
            "    fool: 4\n",
            "    football: 9\n",
            "    for: 5\n",
            "    forest: 7\n",
            "    forever: 6\n",
            "    forget: 7\n",
            "    forgive: 5\n",
            "    form: 9\n",
            "    former: 5\n",
            "    four: 5\n",
            "    fourth: 4\n",
            "    fox: 7\n",
            "    france: 6\n",
            "    freeze: 7\n",
            "    french: 5\n",
            "    french fries: 6\n",
            "    friday: 6\n",
            "    friend: 7\n",
            "    friendly: 6\n",
            "    frog: 7\n",
            "    from: 7\n",
            "    from now on: 5\n",
            "    front: 8\n",
            "    fruit: 7\n",
            "    full: 10\n",
            "    fun: 7\n",
            "    function: 6\n",
            "    funeral: 5\n",
            "    funny: 5\n",
            "    future: 9\n",
            "    gamble: 4\n",
            "    game: 6\n",
            "    gas: 7\n",
            "    gather: 6\n",
            "    general: 6\n",
            "    geography: 7\n",
            "    geometry: 5\n",
            "    german: 5\n",
            "    germany: 5\n",
            "    get: 7\n",
            "    get up: 6\n",
            "    ghost: 6\n",
            "    giraffe: 7\n",
            "    girl: 9\n",
            "    girlfriend: 5\n",
            "    give: 10\n",
            "    give up: 4\n",
            "    glass: 7\n",
            "    glasses: 9\n",
            "    go: 15\n",
            "    goal: 7\n",
            "    goat: 6\n",
            "    god: 7\n",
            "    golf: 7\n",
            "    gone: 5\n",
            "    good: 9\n",
            "    goodbye: 5\n",
            "    gorilla: 5\n",
            "    gossip: 6\n",
            "    government: 9\n",
            "    graduate: 10\n",
            "    graduation: 5\n",
            "    grammar: 8\n",
            "    grandfather: 7\n",
            "    grandmother: 7\n",
            "    grapes: 7\n",
            "    grass: 5\n",
            "    grateful: 5\n",
            "    gray: 6\n",
            "    great: 9\n",
            "    greece: 7\n",
            "    green: 7\n",
            "    group: 8\n",
            "    grow: 6\n",
            "    guess: 6\n",
            "    guide: 5\n",
            "    guilty: 7\n",
            "    guitar: 7\n",
            "    gum: 6\n",
            "    hair: 9\n",
            "    half: 5\n",
            "    halloween: 9\n",
            "    hamburger: 6\n",
            "    hammer: 5\n",
            "    happen: 6\n",
            "    happy: 8\n",
            "    hard: 5\n",
            "    hard of hearing: 4\n",
            "    hat: 8\n",
            "    have: 6\n",
            "    hawaii: 7\n",
            "    head: 6\n",
            "    headache: 9\n",
            "    health: 6\n",
            "    heap: 5\n",
            "    hear: 9\n",
            "    hearing: 8\n",
            "    hearing aid: 5\n",
            "    heart: 8\n",
            "    heart attack: 5\n",
            "    heaven: 5\n",
            "    heavy: 5\n",
            "    helicopter: 8\n",
            "    helmet: 5\n",
            "    help: 14\n",
            "    her: 8\n",
            "    here: 7\n",
            "    herself: 7\n",
            "    hide: 5\n",
            "    high: 5\n",
            "    highway: 7\n",
            "    history: 8\n",
            "    hit: 6\n",
            "    hockey: 5\n",
            "    hold: 5\n",
            "    holy: 5\n",
            "    home: 7\n",
            "    homework: 5\n",
            "    honest: 5\n",
            "    honey: 5\n",
            "    honor: 6\n",
            "    hope: 9\n",
            "    hospital: 7\n",
            "    host: 5\n",
            "    hot: 10\n",
            "    hot dog: 5\n",
            "    hour: 7\n",
            "    house: 7\n",
            "    how: 9\n",
            "    hug: 5\n",
            "    humble: 8\n",
            "    hungry: 6\n",
            "    hunt: 5\n",
            "    hurricane: 5\n",
            "    hurry: 6\n",
            "    hurt: 5\n",
            "    husband: 7\n",
            "    ice cream: 7\n",
            "    idea: 7\n",
            "    identify: 5\n",
            "    if: 5\n",
            "    ignore: 5\n",
            "    illegal: 4\n",
            "    image: 5\n",
            "    impact: 5\n",
            "    important: 8\n",
            "    impossible: 6\n",
            "    improve: 9\n",
            "    in: 7\n",
            "    increase: 5\n",
            "    independent: 7\n",
            "    infection: 6\n",
            "    influence: 6\n",
            "    inform: 9\n",
            "    information: 7\n",
            "    insect: 5\n",
            "    inside: 6\n",
            "    inspect: 5\n",
            "    inspire: 5\n",
            "    instead: 5\n",
            "    institute: 5\n",
            "    insurance: 6\n",
            "    interest: 10\n",
            "    interesting: 6\n",
            "    internet: 8\n",
            "    interpreter: 5\n",
            "    interrupt: 5\n",
            "    interview: 5\n",
            "    introduce: 6\n",
            "    invest: 7\n",
            "    investigate: 6\n",
            "    invite: 5\n",
            "    involve: 5\n",
            "    iran: 7\n",
            "    island: 6\n",
            "    israel: 5\n",
            "    italy: 5\n",
            "    jacket: 7\n",
            "    jail: 5\n",
            "    january: 5\n",
            "    japan: 7\n",
            "    jealous: 8\n",
            "    jesus: 6\n",
            "    jewelry: 6\n",
            "    jewish: 5\n",
            "    join: 8\n",
            "    joke: 5\n",
            "    joy: 5\n",
            "    judge: 5\n",
            "    jump: 6\n",
            "    june: 5\n",
            "    keep: 6\n",
            "    key: 6\n",
            "    keyboard: 6\n",
            "    kick: 5\n",
            "    kid: 5\n",
            "    kill: 6\n",
            "    kindergarten: 5\n",
            "    king: 7\n",
            "    kiss: 9\n",
            "    kitchen: 7\n",
            "    knife: 6\n",
            "    know: 8\n",
            "    label: 6\n",
            "    lady: 5\n",
            "    land: 6\n",
            "    language: 10\n",
            "    laptop: 6\n",
            "    large: 7\n",
            "    last: 12\n",
            "    last week: 5\n",
            "    last year: 6\n",
            "    late: 8\n",
            "    later: 11\n",
            "    laugh: 11\n",
            "    law: 7\n",
            "    lawyer: 5\n",
            "    lazy: 6\n",
            "    lead: 7\n",
            "    leader: 5\n",
            "    leaf: 6\n",
            "    leak: 4\n",
            "    learn: 8\n",
            "    leave: 11\n",
            "    lecture: 7\n",
            "    left: 5\n",
            "    lemon: 8\n",
            "    lend: 6\n",
            "    lesbian: 6\n",
            "    less: 5\n",
            "    lesson: 6\n",
            "    letter: 11\n",
            "    lettuce: 7\n",
            "    liability: 5\n",
            "    library: 5\n",
            "    lie: 7\n",
            "    lift: 6\n",
            "    light: 8\n",
            "    lightning: 6\n",
            "    like: 10\n",
            "    limit: 7\n",
            "    line: 6\n",
            "    linguistics: 7\n",
            "    lion: 5\n",
            "    list: 9\n",
            "    listen: 7\n",
            "    live: 6\n",
            "    lobster: 7\n",
            "    lock: 6\n",
            "    lonely: 6\n",
            "    long: 5\n",
            "    lose: 9\n",
            "    loud: 6\n",
            "    lousy: 5\n",
            "    love: 7\n",
            "    lucky: 6\n",
            "    lunch: 6\n",
            "    machine: 6\n",
            "    mad: 4\n",
            "    magazine: 5\n",
            "    magic: 5\n",
            "    mainstream: 4\n",
            "    major: 5\n",
            "    make: 9\n",
            "    man: 12\n",
            "    manage: 5\n",
            "    manager: 5\n",
            "    many: 10\n",
            "    march: 7\n",
            "    marry: 7\n",
            "    match: 8\n",
            "    math: 7\n",
            "    maximum: 6\n",
            "    maybe: 6\n",
            "    mean: 7\n",
            "    measure: 7\n",
            "    meat: 8\n",
            "    mechanic: 6\n",
            "    medicine: 8\n",
            "    meet: 9\n",
            "    meeting: 6\n",
            "    melody: 5\n",
            "    member: 5\n",
            "    memorize: 7\n",
            "    message: 5\n",
            "    mexico: 6\n",
            "    microphone: 4\n",
            "    microwave: 7\n",
            "    middle: 7\n",
            "    milk: 5\n",
            "    mind: 5\n",
            "    minute: 9\n",
            "    mirror: 8\n",
            "    miss: 8\n",
            "    mix: 6\n",
            "    mom: 7\n",
            "    monday: 6\n",
            "    money: 6\n",
            "    monkey: 7\n",
            "    monster: 5\n",
            "    month: 7\n",
            "    moon: 7\n",
            "    more: 8\n",
            "    morning: 6\n",
            "    most: 7\n",
            "    mother: 11\n",
            "    motivate: 6\n",
            "    motor: 5\n",
            "    motorcycle: 7\n",
            "    mountain: 5\n",
            "    mouse: 5\n",
            "    mouth: 5\n",
            "    move: 10\n",
            "    movie: 5\n",
            "    much: 6\n",
            "    multiply: 6\n",
            "    muscle: 5\n",
            "    museum: 5\n",
            "    mushroom: 5\n",
            "    music: 8\n",
            "    must: 7\n",
            "    mustache: 4\n",
            "    my: 6\n",
            "    myself: 6\n",
            "    name: 6\n",
            "    napkin: 7\n",
            "    nation: 5\n",
            "    near: 9\n",
            "    neck: 6\n",
            "    necklace: 9\n",
            "    need: 6\n",
            "    negative: 7\n",
            "    neighbor: 7\n",
            "    nephew: 6\n",
            "    nervous: 7\n",
            "    network: 6\n",
            "    neutral: 6\n",
            "    never: 7\n",
            "    new: 9\n",
            "    next: 5\n",
            "    nice: 6\n",
            "    niece: 7\n",
            "    night: 5\n",
            "    nine: 5\n",
            "    nineteen: 6\n",
            "    no: 11\n",
            "    none: 7\n",
            "    noon: 6\n",
            "    normal: 5\n",
            "    north: 7\n",
            "    nose: 6\n",
            "    not: 6\n",
            "    nothing: 6\n",
            "    notice: 6\n",
            "    november: 5\n",
            "    now: 9\n",
            "    number: 5\n",
            "    numerous: 5\n",
            "    nurse: 6\n",
            "    nut: 5\n",
            "    obsess: 7\n",
            "    obtain: 5\n",
            "    ocean: 5\n",
            "    october: 5\n",
            "    octopus: 5\n",
            "    odor: 5\n",
            "    off: 7\n",
            "    offer: 6\n",
            "    office: 9\n",
            "    often: 6\n",
            "    ok: 7\n",
            "    old: 7\n",
            "    on: 5\n",
            "    once: 5\n",
            "    one: 8\n",
            "    onion: 8\n",
            "    only: 6\n",
            "    open: 7\n",
            "    operate: 6\n",
            "    opinion: 6\n",
            "    opposite: 5\n",
            "    orange: 10\n",
            "    order: 10\n",
            "    organize: 5\n",
            "    other: 5\n",
            "    out: 5\n",
            "    outside: 9\n",
            "    over: 6\n",
            "    overcome: 5\n",
            "    overlook: 4\n",
            "    overwhelm: 8\n",
            "    owe: 5\n",
            "    owl: 5\n",
            "    pack: 5\n",
            "    page: 5\n",
            "    pain: 5\n",
            "    paint: 7\n",
            "    painter: 5\n",
            "    pants: 8\n",
            "    paper: 8\n",
            "    parade: 6\n",
            "    paragraph: 5\n",
            "    parallel: 5\n",
            "    party: 9\n",
            "    pass: 7\n",
            "    past: 9\n",
            "    path: 6\n",
            "    patient: 7\n",
            "    pause: 5\n",
            "    pay: 7\n",
            "    peaceful: 7\n",
            "    peach: 6\n",
            "    peanut butter: 5\n",
            "    pencil: 5\n",
            "    pennsylvania: 5\n",
            "    people: 6\n",
            "    pepper: 7\n",
            "    perfect: 7\n",
            "    perfume: 5\n",
            "    period: 5\n",
            "    person: 7\n",
            "    perspective: 10\n",
            "    pet: 5\n",
            "    philosophy: 6\n",
            "    phone: 5\n",
            "    photographer: 5\n",
            "    phrase: 6\n",
            "    physician: 6\n",
            "    physics: 6\n",
            "    piano: 5\n",
            "    pick: 5\n",
            "    picture: 6\n",
            "    pie: 5\n",
            "    pig: 7\n",
            "    pillow: 7\n",
            "    pink: 8\n",
            "    pity: 5\n",
            "    pizza: 12\n",
            "    place: 5\n",
            "    plan: 7\n",
            "    plant: 5\n",
            "    plate: 5\n",
            "    play: 11\n",
            "    please: 7\n",
            "    plenty: 5\n",
            "    plus: 7\n",
            "    pneumonia: 5\n",
            "    pocket: 6\n",
            "    point: 9\n",
            "    polar bear: 5\n",
            "    police: 8\n",
            "    policeman: 5\n",
            "    policy: 6\n",
            "    polite: 5\n",
            "    politics: 6\n",
            "    poop: 5\n",
            "    poor: 6\n",
            "    popular: 6\n",
            "    positive: 5\n",
            "    possible: 7\n",
            "    postpone: 8\n",
            "    potato: 8\n",
            "    potential: 5\n",
            "    pound: 6\n",
            "    pour: 5\n",
            "    power: 7\n",
            "    practice: 9\n",
            "    praise: 5\n",
            "    pray: 5\n",
            "    preach: 5\n",
            "    precious: 5\n",
            "    precipitation: 6\n",
            "    predict: 6\n",
            "    pregnant: 5\n",
            "    prepare: 7\n",
            "    present: 8\n",
            "    presentation: 8\n",
            "    president: 9\n",
            "    pressure: 5\n",
            "    pretty: 5\n",
            "    prevent: 5\n",
            "    price: 6\n",
            "    pride: 5\n",
            "    priest: 5\n",
            "    principal: 5\n",
            "    principle: 5\n",
            "    print: 6\n",
            "    printer: 6\n",
            "    prison: 6\n",
            "    private: 7\n",
            "    problem: 9\n",
            "    procrastinate: 7\n",
            "    professional: 7\n",
            "    professor: 5\n",
            "    program: 6\n",
            "    project: 7\n",
            "    promise: 5\n",
            "    proof: 6\n",
            "    protect: 6\n",
            "    proud: 5\n",
            "    prove: 5\n",
            "    provide: 6\n",
            "    psychology: 6\n",
            "    public: 5\n",
            "    publish: 6\n",
            "    pull: 9\n",
            "    pumpkin: 5\n",
            "    punish: 6\n",
            "    purple: 8\n",
            "    purpose: 6\n",
            "    push: 6\n",
            "    put: 6\n",
            "    put off: 5\n",
            "    puzzled: 6\n",
            "    quality: 5\n",
            "    quarter: 5\n",
            "    queen: 6\n",
            "    question: 4\n",
            "    quick: 7\n",
            "    quiet: 7\n",
            "    quit: 7\n",
            "    quote: 5\n",
            "    rabbit: 8\n",
            "    raccoon: 7\n",
            "    race: 6\n",
            "    radio: 6\n",
            "    rain: 7\n",
            "    rainbow: 5\n",
            "    rake: 5\n",
            "    rat: 5\n",
            "    read: 6\n",
            "    ready: 10\n",
            "    really: 7\n",
            "    reason: 7\n",
            "    receive: 5\n",
            "    recent: 7\n",
            "    recognize: 5\n",
            "    recover: 6\n",
            "    red: 7\n",
            "    reduce: 5\n",
            "    refer: 5\n",
            "    referee: 5\n",
            "    refuse: 5\n",
            "    rehearse: 7\n",
            "    reject: 5\n",
            "    relate: 5\n",
            "    relationship: 5\n",
            "    release: 5\n",
            "    relief: 5\n",
            "    religion: 7\n",
            "    rely: 5\n",
            "    remember: 7\n",
            "    remote control: 5\n",
            "    remove: 7\n",
            "    rent: 5\n",
            "    repeat: 5\n",
            "    replace: 5\n",
            "    represent: 7\n",
            "    reputation: 5\n",
            "    require: 6\n",
            "    research: 7\n",
            "    resign: 5\n",
            "    respect: 7\n",
            "    responsibility: 6\n",
            "    rest: 5\n",
            "    restaurant: 7\n",
            "    result: 7\n",
            "    retire: 7\n",
            "    reveal: 5\n",
            "    revenge: 6\n",
            "    review: 7\n",
            "    rich: 6\n",
            "    ride: 8\n",
            "    right: 9\n",
            "    ring: 5\n",
            "    rise: 7\n",
            "    river: 5\n",
            "    rob: 8\n",
            "    robber: 5\n",
            "    rock: 6\n",
            "    role: 4\n",
            "    room: 11\n",
            "    roommate: 5\n",
            "    rooster: 4\n",
            "    rose: 5\n",
            "    rough: 7\n",
            "    rubber: 5\n",
            "    rude: 6\n",
            "    rule: 6\n",
            "    run: 7\n",
            "    rush: 5\n",
            "    russia: 8\n",
            "    sad: 8\n",
            "    safe: 5\n",
            "    salad: 6\n",
            "    salary: 5\n",
            "    salt: 8\n",
            "    same: 9\n",
            "    sandwich: 10\n",
            "    satisfy: 5\n",
            "    saturday: 7\n",
            "    save: 8\n",
            "    say: 6\n",
            "    scared: 8\n",
            "    schedule: 4\n",
            "    school: 9\n",
            "    science: 7\n",
            "    scientist: 4\n",
            "    scissors: 8\n",
            "    score: 11\n",
            "    scotland: 6\n",
            "    screwdriver: 6\n",
            "    sculpture: 6\n",
            "    sea: 5\n",
            "    search: 5\n",
            "    second: 6\n",
            "    secret: 7\n",
            "    secretary: 9\n",
            "    see: 5\n",
            "    seem: 6\n",
            "    selfish: 5\n",
            "    sell: 7\n",
            "    senate: 5\n",
            "    send: 5\n",
            "    senior: 6\n",
            "    sensitive: 5\n",
            "    sentence: 7\n",
            "    separate: 5\n",
            "    september: 5\n",
            "    sequence: 5\n",
            "    serious: 6\n",
            "    serve: 5\n",
            "    service: 7\n",
            "    seven: 6\n",
            "    shame: 5\n",
            "    shampoo: 5\n",
            "    shape: 7\n",
            "    share: 7\n",
            "    she: 6\n",
            "    sheep: 5\n",
            "    shelf: 5\n",
            "    shine: 8\n",
            "    shirt: 12\n",
            "    shock: 9\n",
            "    shoes: 6\n",
            "    shoot: 5\n",
            "    shop: 6\n",
            "    short: 13\n",
            "    should: 6\n",
            "    show: 9\n",
            "    shower: 5\n",
            "    shrimp: 6\n",
            "    shy: 6\n",
            "    sick: 8\n",
            "    side: 3\n",
            "    sign: 9\n",
            "    sign language: 5\n",
            "    silent: 5\n",
            "    silly: 10\n",
            "    silver: 6\n",
            "    similar: 6\n",
            "    simple: 5\n",
            "    since: 8\n",
            "    sing: 5\n",
            "    single: 6\n",
            "    siren: 6\n",
            "    sister: 7\n",
            "    sit: 6\n",
            "    situation: 6\n",
            "    six: 6\n",
            "    sixteen: 6\n",
            "    size: 5\n",
            "    skeleton: 5\n",
            "    sketch: 6\n",
            "    skin: 5\n",
            "    skinny: 6\n",
            "    skirt: 6\n",
            "    skunk: 5\n",
            "    sky: 7\n",
            "    slave: 6\n",
            "    sleep: 6\n",
            "    sleepy: 5\n",
            "    slip: 6\n",
            "    slow: 8\n",
            "    small: 8\n",
            "    smart: 8\n",
            "    smell: 4\n",
            "    smile: 7\n",
            "    smooth: 5\n",
            "    snack: 5\n",
            "    snake: 7\n",
            "    snob: 5\n",
            "    snow: 10\n",
            "    snowman: 5\n",
            "    soap: 7\n",
            "    soccer: 5\n",
            "    society: 5\n",
            "    socks: 6\n",
            "    soda: 6\n",
            "    soft: 8\n",
            "    solid: 6\n",
            "    some: 7\n",
            "    someday: 5\n",
            "    sometimes: 5\n",
            "    son: 10\n",
            "    song: 5\n",
            "    soon: 11\n",
            "    sore throat: 5\n",
            "    sorry: 7\n",
            "    soul: 5\n",
            "    sound: 6\n",
            "    soup: 6\n",
            "    sour: 7\n",
            "    south: 7\n",
            "    south america: 6\n",
            "    spain: 6\n",
            "    spanish: 5\n",
            "    speak: 5\n",
            "    special: 8\n",
            "    specific: 6\n",
            "    speech: 10\n",
            "    speed: 5\n",
            "    spell: 6\n",
            "    spider: 6\n",
            "    spin: 8\n",
            "    spirit: 7\n",
            "    spray: 8\n",
            "    spring: 6\n",
            "    sprint: 6\n",
            "    square: 5\n",
            "    squirrel: 6\n",
            "    stadium: 6\n",
            "    staff: 5\n",
            "    stairs: 6\n",
            "    stamp: 5\n",
            "    stand: 5\n",
            "    standard: 5\n",
            "    star: 6\n",
            "    stare: 7\n",
            "    stay: 9\n",
            "    steal: 7\n",
            "    steel: 6\n",
            "    sticky: 5\n",
            "    still: 5\n",
            "    stink: 8\n",
            "    stomach: 7\n",
            "    stop: 5\n",
            "    store: 7\n",
            "    story: 7\n",
            "    straight: 7\n",
            "    strange: 7\n",
            "    straw: 7\n",
            "    strawberry: 8\n",
            "    street: 6\n",
            "    stress: 7\n",
            "    strict: 6\n",
            "    strong: 8\n",
            "    structure: 6\n",
            "    struggle: 6\n",
            "    stubborn: 7\n",
            "    student: 8\n",
            "    study: 10\n",
            "    stupid: 5\n",
            "    subtract: 6\n",
            "    subway: 5\n",
            "    suffer: 5\n",
            "    sugar: 7\n",
            "    suggest: 6\n",
            "    summer: 7\n",
            "    summon: 5\n",
            "    sun: 6\n",
            "    sunday: 8\n",
            "    sunset: 8\n",
            "    sunshine: 5\n",
            "    support: 6\n",
            "    sure: 5\n",
            "    surface: 5\n",
            "    surgery: 7\n",
            "    surprise: 6\n",
            "    suspect: 6\n",
            "    swallow: 7\n",
            "    sweater: 6\n",
            "    sweet: 10\n",
            "    sweetheart: 6\n",
            "    swimming: 6\n",
            "    swimsuit: 5\n",
            "    switzerland: 5\n",
            "    symbol: 6\n",
            "    table: 5\n",
            "    take: 11\n",
            "    take turns: 7\n",
            "    tale: 6\n",
            "    talk: 5\n",
            "    tall: 13\n",
            "    tan: 5\n",
            "    taste: 4\n",
            "    tea: 7\n",
            "    teach: 7\n",
            "    teacher: 8\n",
            "    team: 5\n",
            "    tease: 8\n",
            "    technology: 5\n",
            "    telephone: 6\n",
            "    telescope: 5\n",
            "    television: 6\n",
            "    tell: 10\n",
            "    temperature: 8\n",
            "    temple: 6\n",
            "    ten: 5\n",
            "    tender: 6\n",
            "    tennis: 6\n",
            "    tent: 7\n",
            "    terrible: 6\n",
            "    test: 8\n",
            "    testify: 4\n",
            "    text: 6\n",
            "    thailand: 6\n",
            "    thank you: 7\n",
            "    thankful: 5\n",
            "    thanksgiving: 12\n",
            "    their: 5\n",
            "    them: 5\n",
            "    theme: 5\n",
            "    themselves: 7\n",
            "    then: 5\n",
            "    theory: 9\n",
            "    therapy: 6\n",
            "    there: 5\n",
            "    thermometer: 5\n",
            "    they: 5\n",
            "    thick: 5\n",
            "    thin: 15\n",
            "    thing: 6\n",
            "    think: 7\n",
            "    third: 7\n",
            "    thirsty: 8\n",
            "    thousand: 6\n",
            "    three: 7\n",
            "    thrill: 5\n",
            "    throat: 5\n",
            "    through: 5\n",
            "    throw: 7\n",
            "    thursday: 11\n",
            "    ticket: 6\n",
            "    tie: 6\n",
            "    tiger: 9\n",
            "    time: 7\n",
            "    tired: 7\n",
            "    tissue: 6\n",
            "    title: 5\n",
            "    to: 7\n",
            "    toast: 10\n",
            "    today: 9\n",
            "    together: 6\n",
            "    toilet: 5\n",
            "    tomato: 8\n",
            "    tomorrow: 7\n",
            "    tongue: 4\n",
            "    tonight: 5\n",
            "    tooth: 5\n",
            "    toothbrush: 5\n",
            "    top: 6\n",
            "    topic: 7\n",
            "    tornado: 5\n",
            "    total: 5\n",
            "    touch: 4\n",
            "    tough: 6\n",
            "    tournament: 6\n",
            "    towel: 5\n",
            "    town: 9\n",
            "    trade: 13\n",
            "    tradition: 5\n",
            "    traffic: 6\n",
            "    train: 9\n",
            "    tranquil: 5\n",
            "    transfer: 8\n",
            "    translate: 7\n",
            "    travel: 8\n",
            "    tree: 6\n",
            "    triangle: 6\n",
            "    trip: 5\n",
            "    trophy: 5\n",
            "    trouble: 5\n",
            "    truck: 6\n",
            "    true: 4\n",
            "    trust: 6\n",
            "    truth: 5\n",
            "    try: 5\n",
            "    tuesday: 6\n",
            "    turkey: 7\n",
            "    turtle: 5\n",
            "    tutor: 5\n",
            "    twin: 5\n",
            "    two: 6\n",
            "    type: 5\n",
            "    ugly: 8\n",
            "    umbrella: 6\n",
            "    uncle: 6\n",
            "    under: 5\n",
            "    understand: 6\n",
            "    underwear: 8\n",
            "    unique: 6\n",
            "    united states: 5\n",
            "    university: 7\n",
            "    until: 7\n",
            "    up: 7\n",
            "    upset: 9\n",
            "    use: 5\n",
            "    vacation: 6\n",
            "    vampire: 5\n",
            "    vegetable: 5\n",
            "    very: 6\n",
            "    viewpoint: 5\n",
            "    violin: 7\n",
            "    visit: 9\n",
            "    visitor: 5\n",
            "    visualize: 5\n",
            "    vocabulary: 6\n",
            "    voice: 9\n",
            "    volleyball: 5\n",
            "    volunteer: 7\n",
            "    vomit: 8\n",
            "    vote: 8\n",
            "    wait: 10\n",
            "    wake up: 5\n",
            "    walk: 11\n",
            "    wall: 5\n",
            "    wallet: 6\n",
            "    wander: 5\n",
            "    want: 9\n",
            "    war: 7\n",
            "    warm: 5\n",
            "    warn: 5\n",
            "    wash: 6\n",
            "    washington: 4\n",
            "    waste: 5\n",
            "    watch: 8\n",
            "    water: 9\n",
            "    waterfall: 5\n",
            "    watermelon: 5\n",
            "    way: 5\n",
            "    we: 7\n",
            "    weak: 7\n",
            "    wear: 6\n",
            "    weather: 8\n",
            "    wedding: 7\n",
            "    wednesday: 8\n",
            "    week: 9\n",
            "    weekend: 9\n",
            "    weight: 6\n",
            "    weird: 5\n",
            "    welcome: 5\n",
            "    west: 8\n",
            "    wet: 8\n",
            "    whale: 5\n",
            "    what: 12\n",
            "    when: 8\n",
            "    where: 7\n",
            "    which: 6\n",
            "    while: 6\n",
            "    white: 10\n",
            "    who: 12\n",
            "    why: 11\n",
            "    wide: 6\n",
            "    wife: 8\n",
            "    willing: 6\n",
            "    win: 7\n",
            "    wind: 8\n",
            "    window: 6\n",
            "    wine: 5\n",
            "    winter: 6\n",
            "    with: 8\n",
            "    within: 5\n",
            "    without: 7\n",
            "    witness: 6\n",
            "    wolf: 5\n",
            "    woman: 11\n",
            "    wonder: 5\n",
            "    wonderful: 6\n",
            "    wood: 6\n",
            "    word: 8\n",
            "    work: 10\n",
            "    worker: 5\n",
            "    workshop: 5\n",
            "    world: 6\n",
            "    worm: 6\n",
            "    worry: 5\n",
            "    worse: 6\n",
            "    worthless: 5\n",
            "    wow: 9\n",
            "    wrap: 5\n",
            "    wristwatch: 6\n",
            "    write: 10\n",
            "    wrong: 8\n",
            "    year: 10\n",
            "    yellow: 8\n",
            "    yes: 11\n",
            "    yesterday: 10\n",
            "    you: 8\n",
            "    young: 5\n",
            "    your: 6\n",
            "    yourself: 5\n"
          ]
        }
      ],
      "source": [
        "# Build detector\n",
        "print(\"Initializing MediaPipe hand detector...\")\n",
        "detector = build_detector(\"hand_landmarker.task\")\n",
        "print(\"Detector ready\")\n",
        "\n",
        "# Process videos\n",
        "print(\"\\nProcessing videos...\")\n",
        "sequences = []\n",
        "labels = []\n",
        "video_ids = []\n",
        "per_gloss_counts = Counter()\n",
        "\n",
        "total_processed = 0\n",
        "total_skipped = 0\n",
        "\n",
        "for entry in metadata:\n",
        "    gloss = entry.get(\"gloss\", \"\")\n",
        "    if gloss.lower() not in gloss_set:\n",
        "        continue\n",
        "\n",
        "    for instance in entry.get(\"instances\", []):\n",
        "        # Check if we've hit the per-gloss limit\n",
        "        if MAX_SAMPLES_PER_GLOSS and per_gloss_counts[gloss] >= MAX_SAMPLES_PER_GLOSS:\n",
        "            continue\n",
        "\n",
        "        video_id = instance.get(\"video_id\")\n",
        "        if not video_id:\n",
        "            continue\n",
        "\n",
        "        # skip if video was found missing during the Scan phase\n",
        "        if video_id not in valid_video_ids:\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(VIDEO_ROOT, f\"{video_id}.mp4\")\n",
        "        if not os.path.exists(video_path):\n",
        "            print(f\"Missing: {video_path}\")\n",
        "            total_skipped += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            sequence = process_video(\n",
        "                detector=detector,\n",
        "                video_path=video_path,\n",
        "                frame_start=int(instance.get(\"frame_start\", 0) or 0),\n",
        "                frame_end=int(instance.get(\"frame_end\", 0) or 0),\n",
        "                sequence_length=SEQUENCE_LENGTH,\n",
        "                frame_stride=FRAME_STRIDE,\n",
        "            )\n",
        "        except Exception as exc:\n",
        "            print(f\"Failed to process {video_path}: {exc}\")\n",
        "            total_skipped += 1\n",
        "            continue\n",
        "\n",
        "        # Check if sequence has enough valid frames\n",
        "        actual_length = np.count_nonzero(np.linalg.norm(sequence, axis=1))\n",
        "        if actual_length < MIN_FRAMES:\n",
        "            total_skipped += 1\n",
        "            continue\n",
        "\n",
        "        sequences.append(sequence)\n",
        "        labels.append(gloss)\n",
        "        video_ids.append(video_id)\n",
        "        per_gloss_counts[gloss] += 1\n",
        "        total_processed += 1\n",
        "\n",
        "        # Progress update\n",
        "        if total_processed % 50 == 0:\n",
        "            print(f\"  Processed {total_processed} videos...\")\n",
        "\n",
        "print(f\"\\nProcessing complete!\")\n",
        "print(f\"  Total processed: {total_processed}\")\n",
        "print(f\"  Total skipped: {total_skipped}\")\n",
        "\n",
        "# Save to NPZ\n",
        "if not sequences:\n",
        "    raise RuntimeError(\"No sequences were extracted. Check your paths and dataset.\")\n",
        "\n",
        "X = np.stack(sequences).astype(np.float32)\n",
        "y = np.array(labels)\n",
        "vids = np.array(video_ids)\n",
        "\n",
        "final_gloss_list = np.array(sorted(list(gloss_set)))\n",
        "np.savez(OUTPUT_NPZ, sequences=X, labels=y, video_ids=vids, glosses=np.array(glosses_to_keep))\n",
        "\n",
        "print(f\"\\nSaved {X.shape[0]} samples to {OUTPUT_NPZ}\")\n",
        "print(f\"  Sequence shape: {X.shape}\")\n",
        "print(\"\\n  Sample distribution:\")\n",
        "for gloss in sorted(per_gloss_counts):\n",
        "    print(f\"    {gloss}: {per_gloss_counts[gloss]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ca23f9d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca23f9d6",
        "outputId": "eb6924f2-9555-472c-e016-2a0d92f33ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaning up memory...\n",
            "Memory cleanup complete\n",
            "\n",
            "You can now proceed to training!\n"
          ]
        }
      ],
      "source": [
        "# Clean up to free memory\n",
        "import gc\n",
        "\n",
        "print(\"\\nCleaning up memory...\")\n",
        "del detector  # Remove detector object\n",
        "gc.collect()  # Force garbage collection\n",
        "\n",
        "print(\"Memory cleanup complete\")\n",
        "print(\"\\nYou can now proceed to training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6491640d",
      "metadata": {
        "id": "6491640d"
      },
      "source": [
        "### Backup Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6461ae1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6461ae1d",
        "outputId": "fa32a2ff-25b9-4817-d849-875632999db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backup saved to: /content/drive/MyDrive/WLASL Dataset/wlasl_landmarks.npz\n",
            "\n",
            "If your session disconnects, you can restore by running:\n",
            "  !cp '/content/drive/MyDrive/WLASL Dataset/wlasl_landmarks.npz' 'wlasl_landmarks.npz'\n"
          ]
        }
      ],
      "source": [
        "# Copy preprocessed data to Google Drive for safekeeping\n",
        "import shutil\n",
        "\n",
        "BACKUP_PATH = \"/content/drive/MyDrive/WLASL Dataset/wlasl_landmarks.npz\"\n",
        "\n",
        "try:\n",
        "    shutil.copy(OUTPUT_NPZ, BACKUP_PATH)\n",
        "    print(f\"Backup saved to: {BACKUP_PATH}\")\n",
        "    print(\"\\nIf your session disconnects, you can restore by running:\")\n",
        "    print(f\"  !cp '{BACKUP_PATH}' '{OUTPUT_NPZ}'\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not backup to Drive: {e}\")\n",
        "    print(\"  Continuing with local copy only...\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}